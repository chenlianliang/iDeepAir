{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, GRU, Multiply, Reshape\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "# from tcn import TCN\n",
    "%matplotlib inline\n",
    "from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   \n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, GlobalAveragePooling2D,AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "MAX_SENT_LENGTH = 55\n",
    "MAX_SENTS = 24\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from pandas import concat\n",
    "\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#matplotlib inline\n",
    "#参数初始化\n",
    "discfile = '../data/data_wea_time_unify.csv'\n",
    "\n",
    "data = pd.read_csv(discfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "futrue_time=24\n",
    "\n",
    "time_step=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(24,96):\n",
    "    data['PM25_m'+str(i)]=data['PM25_mean'].shift(-i)\n",
    "data=data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data=data.iloc[:,76:]\n",
    "source_data=data.iloc[:,4:58]\n",
    "\n",
    "import copy\n",
    "sd=copy.deepcopy(source_data)\n",
    "td=copy.deepcopy(target_data)\n",
    "\n",
    "td=td.dropna(how='any')\n",
    "# td=std.fit_transform(td)\n",
    "sd=std.fit_transform(sd)\n",
    "# sd=sd.values\n",
    "td=td.values\n",
    "td_test=td[5801:,:futrue_time]   \n",
    "td=td[:5801,:futrue_time]\n",
    "sd_m=[]\n",
    "for i in range(1,MAX_SENTS+1):\n",
    "    locals()['sd'+str(i)]=sd[i-1:5800+i]\n",
    "\n",
    "    sd_m.append(locals()['sd'+str(i)])\n",
    "sd_m=(np.array(sd_m).swapaxes(0,1))\n",
    "\n",
    "\n",
    "######test\n",
    "sd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['sd_t'+str(i)]=sd[5800+i:5969-24+i]\n",
    "    \n",
    "    sd_m_test.append(locals()['sd_t'+str(i)])\n",
    "\n",
    "sd_m_test=(np.array(sd_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wea_data=data.iloc[:,67:75]\n",
    "# wea_data=std.fit_transform(wea_data)\n",
    "# wea_data=pd.DataFrame(wea_data)\n",
    "w=wea_data[['Conditions','Wind Dir','Quality evaluation']]\n",
    "# w=std.fit_transform(w)\n",
    "w_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w'+str(i)]=w[i-1:5800+i].values\n",
    "    \n",
    "    w_m.append(locals()['w'+str(i)])\n",
    "    \n",
    "wea=wea_data[['Dew Point','Humidity','Pressure','Temp.','Wind Speed']]\n",
    "wea=std.fit_transform(wea)\n",
    "wea_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea'+str(i)]=wea[i-1:5800+i]\n",
    "    \n",
    "    wea_m.append(locals()['wea'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data=data.iloc[:,64:67]\n",
    "# time_data=std.fit_transform(time_data)\n",
    "time_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time'+str(i)]=time_data[i-1:5800+i].values\n",
    "    \n",
    "    time_m.append(locals()['time'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m=(np.array(time_m).swapaxes(0,1))\n",
    "w_m=(np.array(w_m).swapaxes(0,1))\n",
    "wea_m=(np.array(wea_m).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time_t'+str(i)]=time_data[5800+i:5969-24+i].values\n",
    "    \n",
    "    time_m_test.append(locals()['time_t'+str(i)])\n",
    "\n",
    "time_m_test=(np.array(time_m_test).swapaxes(0,1))\n",
    "\n",
    "w_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w_t'+str(i)]=w[5800+i:5969-24+i].values\n",
    "    \n",
    "    w_m_test.append(locals()['w_t'+str(i)])\n",
    "\n",
    "w_m_test=(np.array(w_m_test).swapaxes(0,1))\n",
    "\n",
    "wea_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea_t'+str(i)]=wea[5800+i:5969-24+i]\n",
    "    \n",
    "    wea_m_test.append(locals()['wea_t'+str(i)])\n",
    "\n",
    "wea_m_test=(np.array(wea_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "ground = h5py.File('../data/inte_g_12.h5', 'r')\n",
    "g = ground['X']\n",
    "\n",
    "ele_zs = h5py.File('../data/inte_e_zs_12_new.h5', 'r')\n",
    "ezs = ele_zs['X']\n",
    "\n",
    "ele_sd = h5py.File('../data/inte_e_sd_12_new.h5', 'r')\n",
    "esd = ele_sd['X']\n",
    "\n",
    "g_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g'+str(i)]=g[i-1:5800+i]\n",
    "    \n",
    "    g_m.append(locals()['g'+str(i)])\n",
    "g_m=(np.array(g_m).swapaxes(0,1))\n",
    "g_m=g_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ezs_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs'+str(i)]=ezs[i-1:5800+i]\n",
    "    \n",
    "    ezs_m.append(locals()['ezs'+str(i)])\n",
    "ezs_m=(np.array(ezs_m).swapaxes(0,1))\n",
    "\n",
    "ezs_m=ezs_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "esd_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd'+str(i)]=esd[i-1:5800+i]\n",
    "    \n",
    "    esd_m.append(locals()['esd'+str(i)])\n",
    "esd_m=(np.array(esd_m).swapaxes(0,1))\n",
    "\n",
    "esd_m=esd_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ge_m=[ezs_m,esd_m,g_m]\n",
    "\n",
    "ge_m=np.array(ge_m).reshape(5801, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####test\n",
    "g_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g_t'+str(i)]=g[5800+i:5969-24+i]\n",
    "    \n",
    "    g_m_test.append(locals()['g_t'+str(i)])\n",
    "g_m_test=(np.array(g_m_test).swapaxes(0,1))\n",
    "\n",
    "g_m_test=g_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "ezs_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs_t'+str(i)]=ezs[5800+i:5969-24+i]\n",
    "    \n",
    "    ezs_m_test.append(locals()['ezs_t'+str(i)])\n",
    "ezs_m_test=(np.array(ezs_m_test).swapaxes(0,1))\n",
    "\n",
    "ezs_m_test=ezs_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "esd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd_t'+str(i)]=esd[5800+i:5969-24+i]\n",
    "    \n",
    "    esd_m_test.append(locals()['esd_t'+str(i)])\n",
    "esd_m_test=(np.array(esd_m_test).swapaxes(0,1))\n",
    "\n",
    "esd_m_test=esd_m_test.reshape(145, 24, 16,16,1)\n",
    "ge_m_test=[ezs_m_test,esd_m_test,g_m_test]\n",
    "\n",
    "ge_m_test=np.array(ge_m_test).reshape(145, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4640 samples, validate on 1161 samples\n",
      "Epoch 1/80\n",
      " - 41s - loss: 46.8519 - val_loss: 28.5647\n",
      "Epoch 2/80\n",
      " - 37s - loss: 30.1532 - val_loss: 24.9449\n",
      "Epoch 3/80\n",
      " - 36s - loss: 27.9533 - val_loss: 24.1600\n",
      "Epoch 4/80\n",
      " - 40s - loss: 27.2684 - val_loss: 23.9714\n",
      "Epoch 5/80\n",
      " - 40s - loss: 26.3524 - val_loss: 24.1016\n",
      "Epoch 6/80\n",
      " - 40s - loss: 25.5113 - val_loss: 22.7209\n",
      "Epoch 7/80\n",
      " - 40s - loss: 24.8671 - val_loss: 23.1948\n",
      "Epoch 8/80\n",
      " - 38s - loss: 24.2101 - val_loss: 22.2290\n",
      "Epoch 9/80\n",
      " - 40s - loss: 23.6214 - val_loss: 21.7097\n",
      "Epoch 10/80\n",
      " - 36s - loss: 23.0741 - val_loss: 22.2416\n",
      "Epoch 11/80\n",
      " - 40s - loss: 22.5979 - val_loss: 21.7711\n",
      "Epoch 12/80\n",
      " - 40s - loss: 22.1984 - val_loss: 21.6049\n",
      "Epoch 13/80\n",
      " - 40s - loss: 21.7621 - val_loss: 21.1141\n",
      "Epoch 14/80\n",
      " - 40s - loss: 21.5129 - val_loss: 20.5536\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-0445ea7cde62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwea_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mge_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msd_m\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;31m# 绘制训练 & 验证的损失值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(** kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        # W.shape = (time_steps, time_steps)\n",
    "        self.W = self.add_weight(name='att_weight', \n",
    "                                 shape=(input_shape[1], input_shape[1]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = K.permute_dimensions(inputs, (0, 2, 1))\n",
    "        # x.shape = (batch_size, seq_len, time_steps)\n",
    "        # general\n",
    "        a = K.softmax(K.tanh(K.dot(x, self.W)))\n",
    "        a = K.permute_dimensions(a, (0, 2, 1))\n",
    "        outputs = a * inputs\n",
    "        outputs = K.sum(outputs, axis=1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[2]\n",
    "\n",
    "def create_model(learn_rate=0.001, neurons=24, traffic_n=3):\n",
    "#     时间戳模块    \n",
    "    inp_time=Input(shape=(3,))\n",
    "    inp_time1 = Reshape((3,1))(inp_time)\n",
    "    embed_time = Dense(3)(inp_time1)\n",
    "#     embed_time = Dense(3)(embed_time)\n",
    "    embed_time=Flatten()(embed_time)\n",
    "    embed_time=BatchNormalization()(embed_time)\n",
    "    tm=Model(inputs=inp_time, outputs=embed_time)\n",
    "    \n",
    "#     离散型气象数据模块\n",
    "    inp_w=Input(shape=(3,))\n",
    "    embed_w = Reshape((3,1))(inp_w)\n",
    "    embed_w1 = Dense(3)(embed_w)\n",
    "#     embed_w1 = Dense(3)(embed_w1)\n",
    "#     embed_w = Embedding(18, 2, input_length=3)(inp_w)\n",
    "#     embed_w = AttentionLayer()(embed_w)\n",
    "    embed_w2=Flatten()(embed_w1)\n",
    "    embed_w3=BatchNormalization()(embed_w2)\n",
    "    wm=Model(inputs=inp_w, outputs=embed_w3)\n",
    "    \n",
    "#     连续型气象数据模块\n",
    "    inp_we=Input(shape=(5,))\n",
    "#     embed_we = Reshape((5,1))(inp_we)\n",
    "    embed_we=BatchNormalization()(inp_we)\n",
    "#     embed_we = AttentionLayer()(embed_we)\n",
    "#     input_we_time=keras.layers.concatenate([embed_time,embed_w,embed_we])\n",
    "    weam=Model(inputs=inp_we, outputs=embed_we)\n",
    "    \n",
    "    \n",
    "#     交通指数数据模块\n",
    "    inp=Input(shape=(16, 16, 3))\n",
    "    out=Conv2D(filters=1, kernel_size=2, strides=1)(inp)\n",
    "#     print(out.shape)\n",
    "    out=BatchNormalization()(out)\n",
    "    out=LeakyReLU('0.05')(out)\n",
    "#     out=Activation('relu')(out)\n",
    "    # out=MaxPooling2D(pool_size=(3, 3), strides=2)(out)\n",
    "    # print(out.shape)\n",
    "    out=AveragePooling2D()(out)\n",
    "#     out=GlobalAveragePooling2D()(out)\n",
    "    out=Flatten()(out)\n",
    "    out=Dense(traffic_n)(out)\n",
    "    tra=Model(inputs=inp, outputs=out)\n",
    "    \n",
    "#     特征组件\n",
    "    sentence_input = Input(shape=(54+traffic_n,))\n",
    "    # s_input=keras.layers.concatenate([sentence_input])\n",
    "    embed = Reshape((54+traffic_n,1))(sentence_input)\n",
    "    l_dense = TimeDistributed(Dense(32))(embed)\n",
    "    l_att = AttentionLayer()(l_dense)\n",
    "\n",
    "    sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "    \n",
    "    review_input = Input(shape=(MAX_SENTS,54))\n",
    "    r_input = Input(shape=(MAX_SENTS,16, 16, 3))\n",
    "    r_encoder = TimeDistributed(tra)(r_input)\n",
    "    s_input=keras.layers.concatenate([r_encoder,review_input])\n",
    "    \n",
    "    review_encoder = TimeDistributed(sentEncoder)(s_input)\n",
    "    \n",
    "    time_input=Input(shape=(MAX_SENTS,3))\n",
    "    t_encoder = TimeDistributed(tm)(time_input)\n",
    "\n",
    "    w_input=Input(shape=(MAX_SENTS,3))\n",
    "    w_encoder = TimeDistributed(wm)(w_input)\n",
    "\n",
    "    wea_input=Input(shape=(MAX_SENTS,5))\n",
    "    wea_encoder = TimeDistributed(weam)(wea_input)\n",
    "#     we_time_encoder=keras.layers.concatenate([wea_input,review_encoder])\n",
    "#     we_time_encoder=keras.layers.concatenate([t_encoder,w_encoder,wea_input,review_encoder])\n",
    "\n",
    "#     l_lstm_sent = Bidirectional(GRU(50, return_sequences=True))(we_time_encoder)\n",
    "\n",
    "#     l_lstm_sent = Bidirectional(GRU(32, return_sequences=True))(review_encoder)\n",
    "    l_lstm_sent=TCN(padding='same',return_sequences=True)(review_encoder)\n",
    "    we_time_encoder=keras.layers.concatenate([t_encoder,w_encoder,wea_input,l_lstm_sent])\n",
    "\n",
    "    l_dense_sent = TimeDistributed(Dense(64))(we_time_encoder)\n",
    "#     l_dense_sent = TCN(padding='same',return_sequences=True)(we_time_encoder)\n",
    "#     l_att_sent = AttentionLayer()(l_dense_sent)\n",
    "#     l_dense_sent1 = Lambda(lambda x: K.permute_dimensions(x, (0, 2, 1)))(l_dense_sent)\n",
    "#     l_dense_sent2=Activation('tanh')(l_dense_sent1)\n",
    "#     l_dense_sent3=Activation('relu')(l_dense_sent2)\n",
    "    \n",
    "# #     a = K.permute_dimensions(a, (0, 2, 1))\n",
    "#     l_dense_sent4 = Lambda(lambda x: K.permute_dimensions(x, (0, 2, 1)))(l_dense_sent3)\n",
    "#     l_att_sent1 = Dot(axes=1)([l_dense_sent4 ,l_dense_sent])\n",
    "# #     outputs2 = K.sum(outputs1, axis=1)\n",
    "#     l_att_sent = Lambda(lambda x: K.sum(x, axis=1))(l_att_sent1)    \n",
    "    \n",
    "    \n",
    "#     l_dense_sent = Bidirectional(GRU(32, return_sequences=True))(we_time_encoder)\n",
    "\n",
    "    \n",
    "#     l_dense_sent = TimeDistributed(Dense(64))(we_time_encoder)\n",
    "    l_att_sent = AttentionLayer()(l_dense_sent)\n",
    "    preds = Dense(futrue_time)(l_att_sent)\n",
    "    model_1 = Model([time_input,w_input,wea_input,r_input,review_input], preds)\n",
    "    model_1.compile(optimizer=Adam(lr=learn_rate, beta_1=0.99, beta_2=0.999, decay=0.0006),\n",
    "                        loss='mae')\n",
    "    return model_1\n",
    "\n",
    "model=create_model()\n",
    "history=model.fit([time_m,w_m,wea_m,ge_m,sd_m],td, epochs=80, batch_size=128,verbose=2,validation_split=0.2,shuffle=True)\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 24, 16, 16, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, 24, 3)        167         input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 24, 54)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 24, 57)       0           time_distributed_29[0][0]        \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, 24, 32)       3313        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 64)       2112        time_distributed_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 64)       8256        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 24, 64)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 24, 64)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 64)       0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 64)       8256        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 24, 64)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 64)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 64)       0           add_1[0][0]                      \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 64)       8256        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 24, 64)       0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 64)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 64)       0           add_2[0][0]                      \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 64)       8256        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 64)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 24, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 64)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 64)       0           add_3[0][0]                      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 64)       8256        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 24, 64)       0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 24, 64)       0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 64)       0           add_4[0][0]                      \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 24, 64)       8256        add_5[0][0]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 64)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 24, 64)       0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 24, 64)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_49 (InputLayer)           (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 24, 64)       0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, 24, 9)        42          input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, 24, 9)        42          input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           (None, 24, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 64)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 24, 87)       0           time_distributed_31[0][0]        \n",
      "                                                                 time_distributed_32[0][0]        \n",
      "                                                                 input_50[0][0]                   \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, 24, 64)       5632        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_7 (AttentionLay (None, 64)           576         time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 24)           1560        attention_layer_7[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 87,940\n",
      "Trainable params: 87,902\n",
      "Non-trainable params: 38\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.67 29.187\n"
     ]
    }
   ],
   "source": [
    "pre_test=model.predict([time_m_test,w_m_test,wea_m_test,ge_m_test,sd_m_test])\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.round(mean_absolute_error(pre_test,td_test[:145]),3),np.round(np.sqrt(mean_squared_error(pre_test,td_test[:145])),3))\n",
    "# mean_absolute_error(pre_test,td_test[:145]),np.sqrt(mean_squared_error(pre_test,td_test[:145]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = K.function(model.inputs, [model.get_layer('dense_21').get_output_at(0) for t in range(24)])\n",
    "# f = K.function(model.inputs, [model.get_layer('attention_weights3').output])\n",
    "\n",
    "f = K.function(model.inputs, [model.get_layer('concatenate_6').output])\n",
    "\n",
    "t=22\n",
    "\n",
    "# r = f([time_m_test[1].reshape(1,24,3),w_m_test[1].reshape(1,24,3),wea_m_test[1].reshape(1,24,5),ge_m_test[1].reshape(1,24,16,16,3),sd_m_test[1].reshape(1,24,55)])\n",
    "\n",
    "r = f([time_m_test[t].reshape(1,24,3),w_m_test[t].reshape(1,24,3),wea_m_test[t].reshape(1,24,5),ge_m_test[t].reshape(1,24,16,16,3),sd_m_test[t].reshape(1,24,54)])\n",
    "\n",
    "# r = f([time_m,w_m,wea_m,ge_m,sd_m])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.60565114, -1.61168814, -1.60759902, -1.07545018, -1.25474048,\n",
       "       -1.1862427 , -1.9904629 , -2.90479803, -2.04758644,  0.34356499,\n",
       "        0.34838223, -0.67036569,  1.65496063,  1.31778765, -1.70392609,\n",
       "        0.12959051,  0.13021564, -0.13372993,  0.1201181 ,  1.00378025,\n",
       "       -1.24483192, -0.3540802 ,  2.27805638, -0.21498449,  0.2120931 ,\n",
       "       -0.20067246, -0.26316139,  0.28022641, -0.27509746,  0.24655509,\n",
       "       -0.1759035 ,  0.2690005 , -0.0428311 ,  0.12576929, -0.19226445,\n",
       "        0.17452338,  0.10024634, -0.18406463, -0.22333506,  0.25296929,\n",
       "       -0.24071747,  0.05770342, -0.11601439, -0.24185684,  0.16680843,\n",
       "        0.28006658, -0.1369556 ,  0.1928222 ,  0.14782353, -0.23274067,\n",
       "       -0.22320944, -0.14893307,  0.26807362,  0.14763112,  0.25975823,\n",
       "        0.99990451, -0.99979311,  0.9996978 ,  0.999735  , -0.9998799 ,\n",
       "       -0.99996322,  0.99993932, -0.99996531,  0.99980038,  0.99975097,\n",
       "        0.99964315, -0.99981707, -0.99986398,  0.99986184, -0.99991977,\n",
       "        0.99978501,  0.9998666 , -0.99904025,  0.99967605,  0.99998486,\n",
       "        0.99894798,  0.99954355, -0.9999181 ,  0.9999395 ,  0.99997669,\n",
       "        0.99964666, -0.99995571,  0.99279892, -0.99979532, -0.99997413,\n",
       "        0.99985754,  0.99978685], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"lrp.z\", model, allow_lambda_layers = True)\n",
    "analyzer = innvestigate.create_analyzer(\"lrp.z\", model, allow_lambda_layers = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem=sd_m[0].reshape(1,24,54)\n",
    "tem1=ge_m[0].reshape(1,24, 16, 16, 3)\n",
    "tem2=time_m[0].reshape(1,24, 3)\n",
    "tem3=w_m[0].reshape(1,24, 3)\n",
    "tem4=wea_m[0].reshape(1,24,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = analyzer.analyze([tem2,tem3,tem4,tem1,tem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=analysis[0]\n",
    "a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "a /= np.max(np.abs(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 5)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49735832, -0.5265522 , -0.52103627, -0.51862955, -0.52315205,\n",
       "        -0.51850593, -0.51739514, -0.51968604,  0.98840296,  0.9996708 ,\n",
       "         0.99372292,  0.99956232, -0.51374751,  0.99716723,  0.99405044,\n",
       "         0.99603361, -0.50925744, -0.51431334, -0.512025  , -0.51035821,\n",
       "        -0.50560743, -0.50662416, -0.50433177,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from heatmap import html_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce87dd438>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a0=analysis[0]\n",
    "a0 = a0.sum(axis=np.argmax(np.asarray(a0.shape) == 3))\n",
    "a0 /= np.max(np.abs(a0))\n",
    "plt.imshow(a0, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce882a0b8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1=analysis[1]\n",
    "a1 = a1.sum(axis=np.argmax(np.asarray(a1.shape) == 3))\n",
    "a1 /= np.max(np.abs(a1))\n",
    "plt.imshow(a1, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce88c6978>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFIAAAD8CAYAAADkOvMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACN5JREFUeJztnW+IXFcZh5+3ycYWk2ytW5uaBtNKEOMHY1mKWimxpSVGsApVWlAKFWqxAQX9IAoqfuoXlQpSiRpaQU381zRorJZaFYPWxpLWhqCbhmjXpmmiTdKFhmTT1w9zUyab3blnZ357M7P5PTDMnXvfOefcZ+/cOXP3vPdEZmJ654Jz3YD5gkWKsEgRFinCIkVYpAiLFGGRIixSxMImKxsZHs6Vy5Z1jNn17JLacta8+cWyCiPqY44c6bh5/yuvcPjEidqCehIZEeuAe4EFwPcy855O8SuXLWPnffd1LPOSW66vrXfn579V1sALL6yP2bq14+bRHTuKqur6ox0RC4BvAx8AVgO3RcTqbssbdHo5R14D7M3MfZl5AtgM3Kxp1uDRi8jlwHNtr8erdeclvYic7gR81jW5iLgzInZGxM5DNSf2QaYXkePAirbXVwDPTw3KzI2ZOZqZo5defHEP1fU3vYh8AlgVEVdGxCLgVmCbplmDR9fdn8ycjIgNwG9odX82ZeZuWcsGjJ76kZm5Hdg+izfA5GTHkImJgnKOHy+uspbDhztvr2nvafwTUYRFirBIERYpwiJFWKQIixRhkSIavUJOJpw82TFkwYKCckou2JayeHHn7UUN8hEpwyJFWKQIixRhkSIsUoRFirBIEc12yCNgaKjRKmupuwJemKzgI1KERYqwSBEWKcIiRVikCIsUYZEimu2QF3DqVEFQ4TASFhbsXs0Ve3fIG8YiRVikCIsUYZEiLFKERYqwSBF91yEvGiFS0tEu5aKLOm+/oOxY8xEpotfs2P3Ay8ApYDIzRxWNGkQUn5H3Z2ZNjsX8xx9tEb2KTOC3EfG3iLhzuoAzkjqPHu2xuv6lV5HXZubVtJLf746I66YGnJHUOTzcY3X9S08iM/P56vlF4EFayfDnJb3ciuH1EbHk9DJwE/CMqmGDRi/f2pcBD0brTiYLgR9l5sMd31EwhnxQ6SXNeB/wTmFbBhp3f0RYpAiLFGGRIixShEWKsEgRFimi7/7VUERhxmrZQCINPiJFWKQIixRhkSIsUoRFirBIERYpotEO+eGTw2w6+MGOMQeP19+E/aaHygbI799fHzM29oeaCN+uplEsUoRFirBIERYpwiJFWKQIixTRd1fIXy2IKU2OLeNEzXZnxzaKRYqwSBEWKcIiRVikCIsUYZEi+q5DXvKXVSbHwqKa7QXTplLQ7ojYFBEvRsQzbesuiYhHImKsen5DUW3zmJID4H5g3ZR1XwAezcxVwKPV6/OaWpGZ+Ufgf1NW3ww8UC0/AHxY3K6Bo9svm8sy8wBA9fymmQLbkzonJg51WV3/M+ff2u1JnYsXXzrX1Z0zuhV5MCIuB6ieC2cOn790K3IbcHu1fDvwkKY5g0tJ9+fHwJ+Bt0XEeER8ErgHuDEixoAbq9fnNbVd28y8bYZNN4jbUoyvkM9jLFKERYqwSBEWKcIiRVikCIsU0egV8pGho9xx2a86xixdUt8BPnbrxrIKjx+vj3m4c+Ln6A53yBvFIkVYpAiLFGGRIixShEWKsEgRfZfUOf5y/RCR6zeXdZLHx+tjxsYeqYkQDVkxZVikCIsUYZEiLFKERYqwSBEWKaLvxpA3T+EtFGvwESnCIkVYpAiLFGGRIixShEWKsEgR7pCjuVd5t0mdX42I/0TEruqxXtKaAabbpE6Ab2bmmuqxXduswaPbpE4zhV6+bDZExNPVR9/52l2+7z7grcAa4ADw9ZkCnR3bgcw8mJmnMvNV4Lt0mKHT2bEdOJ0ZW/ERzuMZOk9T24+skjrXAiMRMQ58BVgbEWtoJertBz41h20cCLpN6vx+N5WNLDzCHSPbOsYUjSH/+KayCicm6mN+P9Rx8+hjHrLSKBYpwiJFWKQIixRhkSIsUoRFihjMK+TK26zUlZVO6mwUixRhkSIsUoRFirBIERYpwiJFWKQIixRhkSIsUoRFirBIERYpwiJFWKQIixQxmP9qUE6xVFdWeOxPo1ikCIsUYZEiLFKERYqwSBEWKaIkq2EF8ANgGfAqsDEz742IS4AtwEpamQ0fy8yXem5Q0z8RGuyQTwKfy8y3A+8G7o6I1Xi2zjMoSeo8kJlPVssvA3uA5Xi2zjOY1TkyIlYC7wIeZxazdZ4PFIuMiMXAz4HPZuaxWbzvtaTOQ8eK3zZwFImMiCFaEn+Ymb+oVhfN1tme1Hnp0qWKNvclJbdiCFopc3sy8xttmzxbZxslnY1rgU8Af4+IXdW6L9KanfMn1cyd/wY+OjdNHAxKkjr/xMw34z5ns3X2G812fyNggeZ+jTI8GL+/sEgRFinCIkVYpAiLFGGRIixShEWKsEgRFinCIkVYpAiLFGGRIixShEWK6LspT/e9VD9E5Lr7y65av/BCfUz9lKe+Qt4oFinCIkVYpAiLFGGRIixShEWKiCwckiGpLOIQ8K+2VSPA4TmqTlX2WzKzdpKJRkWeVXnEzswcHbSyp8MfbREWKeJci9w4oGWfxTk9R84nzvUROW9oRGRErIuIf0TE3og4K0MsIl4XEVuq7Y9X+Twl5a6IiMciYk9E7I6Iz0wTszYijrbN4fjl3vdoGjJzTh+05qZ/FrgKWAQ8BayeEvNp4DvV8q3AlsKyLweurpaXAP+cpuy1wC/nej+bOCKvAfZm5r7MPAFsppV+1057Ot7PgBuqtJSOdEjva5wmRC4Hnmt7Pc7ZO/taTGZOAkeBN86mkinpfVN5T0Q8FRG/joh3zKbcUpr4n810R9bUrkJJzMwVdE7ve5LWz7yJao7brcCq0rJLaeKIHAdWtL2+Anh+ppiIWAgMUzjN6gzpfa+Rmccyc6Ja3g4MRcTIbHeijiZEPgGsiogrI2IRrS+TqVPRtafj3QL8Lgs6uB3S+9pjlp0+30bENbT2+b9d7Ukn5vrbrPKxntY36rPAl6p1XwM+VC1fCPwU2Av8FbiqsNz30ToFPA3sqh7rgbuAu6qYDcBuWr2FvwDvnYt99C8bEf5lI8IiRVikCIsUYZEiLFKERYqwSBH/Bynsv7Zzulp5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a2=analysis[2]\n",
    "a2 = a2.sum(axis=np.argmax(np.asarray(a2.shape) == 3))\n",
    "a2 /= np.max(np.abs(a2))\n",
    "plt.imshow(a2, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce8a31828>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a3=analysis[3]\n",
    "a3 = a3.sum(axis=np.argmax(np.asarray(a3.shape) == 3))\n",
    "a3 /= np.max(np.abs(a3))\n",
    "# plt.imshow(a2, cmap=\"seismic\", clim=(-1, 1))\n",
    "plt.imshow(a3[0][12], cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#8e8eff\">0</span> <span style=\"background-color:#bebeff\">1</span> <span style=\"background-color:#7070ff\">2</span> <span style=\"background-color:#8888ff\">3</span> <span style=\"background-color:#5151ff\">4</span> <span style=\"background-color:#f6f6ff\">5</span> <span style=\"background-color:#d0d0ff\">6</span> <span style=\"background-color:#9a9aff\">7</span> <span style=\"background-color:#a3a3ff\">8</span> <span style=\"background-color:#b0b0ff\">9</span> <span style=\"background-color:#c2c2ff\">10</span> <span style=\"background-color:#9a9aff\">11</span> <span style=\"background-color:#bcbcff\">12</span> <span style=\"background-color:#6969ff\">13</span> <span style=\"background-color:#ffe2e2\">14</span> <span style=\"background-color:#ff5050\">15</span> <span style=\"background-color:#b0b0ff\">16</span> <span style=\"background-color:#f6f6ff\">17</span> <span style=\"background-color:#ff3636\">18</span> <span style=\"background-color:#ff7c7c\">19</span> <span style=\"background-color:#ff9c9c\">20</span> <span style=\"background-color:#ffb6b6\">21</span> <span style=\"background-color:#ff6666\">22</span> <span style=\"background-color:#fffafa\">23</span> <span style=\"background-color:#ffd3d3\">24</span> <span style=\"background-color:#ff9090\">25</span> <span style=\"background-color:#ffb8b8\">26</span> <span style=\"background-color:#ff2c2c\">27</span> <span style=\"background-color:#ff4444\">28</span> <span style=\"background-color:#a0a0ff\">29</span> <span style=\"background-color:#ff9e9e\">30</span> <span style=\"background-color:#dedeff\">31</span> <span style=\"background-color:#ffaaaa\">32</span> <span style=\"background-color:#fcfcff\">33</span> <span style=\"background-color:#ceceff\">34</span> <span style=\"background-color:#ff9a9a\">35</span> <span style=\"background-color:#ff9c9c\">36</span> <span style=\"background-color:#ffe2e2\">37</span> <span style=\"background-color:#ff7474\">38</span> <span style=\"background-color:#ff8e8e\">39</span> <span style=\"background-color:#ff0c0c\">40</span> <span style=\"background-color:#ff9090\">41</span> <span style=\"background-color:#ff8080\">42</span> <span style=\"background-color:#ff9696\">43</span> <span style=\"background-color:#ff8383\">44</span> <span style=\"background-color:#ff6161\">45</span> <span style=\"background-color:#ffa6a6\">46</span> <span style=\"background-color:#e2e2ff\">47</span> <span style=\"background-color:#ffacac\">48</span> <span style=\"background-color:#8c8cff\">49</span> <span style=\"background-color:#ff4e4e\">50</span> <span style=\"background-color:#ff3030\">51</span> <span style=\"background-color:#ff0000\">52</span> <span style=\"background-color:#fff4f4\">53</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a4=analysis[4]\n",
    "a4 = a4.sum(axis=np.argmax(np.asarray(a4.shape) == 3))\n",
    "a4 /= np.max(np.abs(a4))\n",
    "plt.imshow(a4, cmap=\"seismic\", clim=(-1, 1))\n",
    "\n",
    "\n",
    "display(HTML(html_heatmap([str(i) for i in range(54)], a4[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Convolution1D, Dense\n",
    "from keras.models import Input, Model\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def channel_normalization(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\" Normalize a layer to the maximum activation\n",
    "\n",
    "    This keeps a layers values between zero and one.\n",
    "    It helps with relu's unbounded activation\n",
    "\n",
    "    Args:\n",
    "        x: The layer to normalize\n",
    "\n",
    "    Returns:\n",
    "        A maximal normalized layer\n",
    "    \"\"\"\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "\n",
    "def wave_net_activation(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\"This method defines the activation used for WaveNet\n",
    "\n",
    "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
    "\n",
    "    Args:\n",
    "        x: The layer we want to apply the activation to\n",
    "\n",
    "    Returns:\n",
    "        A new layer with the wavenet activation applied\n",
    "    \"\"\"\n",
    "    tanh_out = Activation('tanh')(x)\n",
    "    sigm_out = Activation('sigmoid')(x)\n",
    "    return keras.layers.multiply([tanh_out, sigm_out])\n",
    "\n",
    "\n",
    "def residual_block(x, s, i, c, activation, nb_filters, kernel_size, padding, dropout_rate=0):\n",
    "    # type: (Layer, int, int, int, str, int, int, str, float, str) -> Tuple[Layer, Layer]\n",
    "    \"\"\"Defines the residual block for the WaveNet TCN\n",
    "\n",
    "    Args:\n",
    "        x: The previous layer in the model\n",
    "        s: The stack index i.e. which stack in the overall TCN\n",
    "        i: The dilation power of 2 we are using for this residual block\n",
    "        c: The dilation name to make it unique. In case we have same dilation twice: [1, 1, 2, 4].\n",
    "        activation: The name of the type of activation to use\n",
    "        nb_filters: The number of convolutional filters to use in this block\n",
    "        kernel_size: The size of the convolutional kernel\n",
    "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A tuple where the first element is the residual model layer, and the second\n",
    "        is the skip connection.\n",
    "    \"\"\"\n",
    "\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding=padding)(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "    elif activation == 'wavenet':\n",
    "        x = wave_net_activation(conv)\n",
    "    else:\n",
    "        x = Activation(activation)(conv)\n",
    "\n",
    "    x = SpatialDropout1D(dropout_rate)(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = keras.layers.add([original_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        # print(f'Updated dilations from {dilations} to {new_dilations} because of backwards compatibility.')\n",
    "        return new_dilations\n",
    "\n",
    "\n",
    "class TCN:\n",
    "    \"\"\"Creates a TCN layer.\n",
    "\n",
    "        Input shape:\n",
    "            A tensor of shape (batch_size, timesteps, input_dim).\n",
    "\n",
    "        Args:\n",
    "            nb_filters: The number of filters to use in the convolutional layers.\n",
    "            kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "            dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "            nb_stacks : The number of stacks of residual blocks to use.\n",
    "            activation: The activations to use (norm_relu, wavenet, relu...).\n",
    "            padding: The padding to use in the convolutional layers, 'causal' or 'same'.\n",
    "            use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "            return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "            name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "        Returns:\n",
    "            A TCN layer.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=[1, 2, 4, 8, 16, 32],\n",
    "                 activation='norm_relu',\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.0,\n",
    "                 return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.activation = activation\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding != 'causal' and padding != 'same':\n",
    "            raise ValueError(\"Only 'causal' or 'same' padding are compatible for this layer.\")\n",
    "\n",
    "        if not isinstance(nb_filters, int):\n",
    "            print('An interface change occurred after the version 2.1.2.')\n",
    "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
    "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
    "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
    "            raise Exception()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        x = Convolution1D(self.nb_filters, 1, padding=self.padding)(x)\n",
    "        skip_connections = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for i, d in enumerate(self.dilations):\n",
    "                x, skip_out = residual_block(x, s, d, i, self.activation, self.nb_filters,\n",
    "                                             self.kernel_size, self.padding, self.dropout_rate)\n",
    "                skip_connections.append(skip_out)\n",
    "        if self.use_skip_connections:\n",
    "            x = keras.layers.add(skip_connections)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        if not self.return_sequences:\n",
    "            output_slice_index = -1\n",
    "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def compiled_tcn(num_feat,  # type: int\n",
    "                 num_classes,  # type: int\n",
    "                 nb_filters,  # type: int\n",
    "                 kernel_size,  # type: int\n",
    "                 dilations,  # type: List[int]\n",
    "                 nb_stacks,  # type: int\n",
    "                 max_len,  # type: int\n",
    "                 activation='norm_relu',  # type: str\n",
    "                 padding='causal',  # type: str\n",
    "                 use_skip_connections=True,  # type: bool\n",
    "                 return_sequences=True,\n",
    "                 regression=False,  # type: bool\n",
    "                 dropout_rate=0.05,  # type: float\n",
    "                 ):\n",
    "    # type: (...) -> keras.Model\n",
    "    \"\"\"Creates a compiled TCN model for a given task (i.e. regression or classification).\n",
    "\n",
    "    Args:\n",
    "        num_feat: The number of features of your input, i.e. the last dimension of: (batch_size, timesteps, input_dim).\n",
    "        num_classes: The size of the final dense layer, how many classes we are predicting.\n",
    "        nb_filters: The number of filters to use in the convolutional layers.\n",
    "        kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "        dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "        nb_stacks : The number of stacks of residual blocks to use.\n",
    "        max_len: The maximum sequence length, use None if the sequence length is dynamic.\n",
    "        activation: The activations to use.\n",
    "        padding: The padding to use in the convolutional layers.\n",
    "        use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "        return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "        regression: Whether the output should be continuous or discrete.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A compiled keras TCN.\n",
    "    \"\"\"\n",
    "\n",
    "    dilations = process_dilations(dilations)\n",
    "\n",
    "    input_layer = Input(shape=(max_len, num_feat))\n",
    "\n",
    "    x = TCN(nb_filters, kernel_size, nb_stacks, dilations, activation,\n",
    "            padding, use_skip_connections, dropout_rate, return_sequences)(input_layer)\n",
    "\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "    if not regression:\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO To remove later.\n",
    "        def accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            if K.ndim(y_true) == K.ndim(y_pred):\n",
    "                y_true = K.squeeze(y_true, -1)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "            y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n",
    "        print('Adam with norm clipping.')\n",
    "    else:\n",
    "        # regression\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('linear')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='mean_squared_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
