{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, GRU, Multiply, Reshape\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "# from tcn import TCN\n",
    "%matplotlib inline\n",
    "from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   \n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, GlobalAveragePooling2D,AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "MAX_SENT_LENGTH = 55\n",
    "MAX_SENTS = 24\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from pandas import concat\n",
    "\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#matplotlib inline\n",
    "#参数初始化\n",
    "discfile = '../data/data_wea_time_unify.csv'\n",
    "\n",
    "data = pd.read_csv(discfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "futrue_time=24\n",
    "\n",
    "time_step=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(24,96):\n",
    "    data['PM25_m'+str(i)]=data['PM25_mean'].shift(-i)\n",
    "data=data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data=data.iloc[:,76:]\n",
    "source_data=data.iloc[:,4:58]\n",
    "\n",
    "import copy\n",
    "sd=copy.deepcopy(source_data)\n",
    "td=copy.deepcopy(target_data)\n",
    "\n",
    "td=td.dropna(how='any')\n",
    "# td=std.fit_transform(td)\n",
    "sd=std.fit_transform(sd)\n",
    "# sd=sd.values\n",
    "td=td.values\n",
    "td_test=td[5801:,:futrue_time]   \n",
    "td=td[:5801,:futrue_time]\n",
    "sd_m=[]\n",
    "for i in range(1,MAX_SENTS+1):\n",
    "    locals()['sd'+str(i)]=sd[i-1:5800+i]\n",
    "\n",
    "    sd_m.append(locals()['sd'+str(i)])\n",
    "sd_m=(np.array(sd_m).swapaxes(0,1))\n",
    "\n",
    "\n",
    "######test\n",
    "sd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['sd_t'+str(i)]=sd[5800+i:5969-24+i]\n",
    "    \n",
    "    sd_m_test.append(locals()['sd_t'+str(i)])\n",
    "\n",
    "sd_m_test=(np.array(sd_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wea_data=data.iloc[:,67:75]\n",
    "# wea_data=std.fit_transform(wea_data)\n",
    "# wea_data=pd.DataFrame(wea_data)\n",
    "w=wea_data[['Conditions','Wind Dir','Quality evaluation']]\n",
    "# w=std.fit_transform(w)\n",
    "w_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w'+str(i)]=w[i-1:5800+i].values\n",
    "    \n",
    "    w_m.append(locals()['w'+str(i)])\n",
    "    \n",
    "wea=wea_data[['Dew Point','Humidity','Pressure','Temp.','Wind Speed']]\n",
    "wea=std.fit_transform(wea)\n",
    "wea_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea'+str(i)]=wea[i-1:5800+i]\n",
    "    \n",
    "    wea_m.append(locals()['wea'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data=data.iloc[:,64:67]\n",
    "# time_data=std.fit_transform(time_data)\n",
    "time_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time'+str(i)]=time_data[i-1:5800+i].values\n",
    "    \n",
    "    time_m.append(locals()['time'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m=(np.array(time_m).swapaxes(0,1))\n",
    "w_m=(np.array(w_m).swapaxes(0,1))\n",
    "wea_m=(np.array(wea_m).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time_t'+str(i)]=time_data[5800+i:5969-24+i].values\n",
    "    \n",
    "    time_m_test.append(locals()['time_t'+str(i)])\n",
    "\n",
    "time_m_test=(np.array(time_m_test).swapaxes(0,1))\n",
    "\n",
    "w_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w_t'+str(i)]=w[5800+i:5969-24+i].values\n",
    "    \n",
    "    w_m_test.append(locals()['w_t'+str(i)])\n",
    "\n",
    "w_m_test=(np.array(w_m_test).swapaxes(0,1))\n",
    "\n",
    "wea_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea_t'+str(i)]=wea[5800+i:5969-24+i]\n",
    "    \n",
    "    wea_m_test.append(locals()['wea_t'+str(i)])\n",
    "\n",
    "wea_m_test=(np.array(wea_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "ground = h5py.File('../data/inte_g_12.h5', 'r')\n",
    "g = ground['X']\n",
    "\n",
    "ele_zs = h5py.File('../data/inte_e_zs_12_new.h5', 'r')\n",
    "ezs = ele_zs['X']\n",
    "\n",
    "ele_sd = h5py.File('../data/inte_e_sd_12_new.h5', 'r')\n",
    "esd = ele_sd['X']\n",
    "\n",
    "g_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g'+str(i)]=g[i-1:5800+i]\n",
    "    \n",
    "    g_m.append(locals()['g'+str(i)])\n",
    "g_m=(np.array(g_m).swapaxes(0,1))\n",
    "g_m=g_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ezs_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs'+str(i)]=ezs[i-1:5800+i]\n",
    "    \n",
    "    ezs_m.append(locals()['ezs'+str(i)])\n",
    "ezs_m=(np.array(ezs_m).swapaxes(0,1))\n",
    "\n",
    "ezs_m=ezs_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "esd_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd'+str(i)]=esd[i-1:5800+i]\n",
    "    \n",
    "    esd_m.append(locals()['esd'+str(i)])\n",
    "esd_m=(np.array(esd_m).swapaxes(0,1))\n",
    "\n",
    "esd_m=esd_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ge_m=[ezs_m,esd_m,g_m]\n",
    "\n",
    "ge_m=np.array(ge_m).reshape(5801, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####test\n",
    "g_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g_t'+str(i)]=g[5800+i:5969-24+i]\n",
    "    \n",
    "    g_m_test.append(locals()['g_t'+str(i)])\n",
    "g_m_test=(np.array(g_m_test).swapaxes(0,1))\n",
    "\n",
    "g_m_test=g_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "ezs_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs_t'+str(i)]=ezs[5800+i:5969-24+i]\n",
    "    \n",
    "    ezs_m_test.append(locals()['ezs_t'+str(i)])\n",
    "ezs_m_test=(np.array(ezs_m_test).swapaxes(0,1))\n",
    "\n",
    "ezs_m_test=ezs_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "esd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd_t'+str(i)]=esd[5800+i:5969-24+i]\n",
    "    \n",
    "    esd_m_test.append(locals()['esd_t'+str(i)])\n",
    "esd_m_test=(np.array(esd_m_test).swapaxes(0,1))\n",
    "\n",
    "esd_m_test=esd_m_test.reshape(145, 24, 16,16,1)\n",
    "ge_m_test=[ezs_m_test,esd_m_test,g_m_test]\n",
    "\n",
    "ge_m_test=np.array(ge_m_test).reshape(145, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4640 samples, validate on 1161 samples\n",
      "Epoch 1/80\n"
     ]
    }
   ],
   "source": [
    "from attention_keras import *\n",
    "from keras.layers import LeakyReLU\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(** kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        # W.shape = (time_steps, time_steps)\n",
    "        self.W = self.add_weight(name='att_weight', \n",
    "                                 shape=(input_shape[1], input_shape[1]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = K.permute_dimensions(inputs, (0, 2, 1))\n",
    "        # x.shape = (batch_size, seq_len, time_steps)\n",
    "        # general\n",
    "        a = K.softmax(K.tanh(K.dot(x, self.W)))\n",
    "        a = K.permute_dimensions(a, (0, 2, 1))\n",
    "        outputs = a * inputs\n",
    "        outputs = K.sum(outputs, axis=1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[2]\n",
    "\n",
    "def create_model(learn_rate=0.001, neurons=24, traffic_n=3):\n",
    "#     时间戳模块    \n",
    "    inp_time=Input(shape=(3,))\n",
    "    inp_time1 = Reshape((3,1))(inp_time)\n",
    "    embed_time = Dense(3)(inp_time1)\n",
    "#     embed_time = Embedding(24,3, input_length=3)(inp_time)\n",
    "    embed_time=Flatten()(embed_time)\n",
    "    embed_time=BatchNormalization()(embed_time)\n",
    "    tm=Model(inputs=inp_time, outputs=embed_time)\n",
    "    \n",
    "#     离散型气象数据模块\n",
    "    inp_w=Input(shape=(3,))\n",
    "    embed_w = Reshape((3,1))(inp_w)\n",
    "    embed_w1 = Dense(3)(embed_w)\n",
    "#     embed_w1 = Dense(3)(embed_w1)\n",
    "#     embed_w = Embedding(18, 2, input_length=3)(inp_w)\n",
    "#     embed_w = AttentionLayer()(embed_w)\n",
    "    embed_w2=Flatten()(embed_w1)\n",
    "    embed_w3=BatchNormalization()(embed_w2)\n",
    "    wm=Model(inputs=inp_w, outputs=embed_w3)\n",
    "    \n",
    "#     连续型气象数据模块\n",
    "    inp_we=Input(shape=(5,))\n",
    "    embed_we = Reshape((5,1))(inp_we)\n",
    "    embed_we=BatchNormalization()(embed_we)\n",
    "    embed_we = AttentionLayer()(embed_we)\n",
    "#     input_we_time=keras.layers.concatenate([embed_time,embed_w,embed_we])\n",
    "    weam=Model(inputs=inp_we, outputs=embed_we)\n",
    "    \n",
    "    \n",
    "#     交通指数数据模块\n",
    "    inp=Input(shape=(16, 16, 3))\n",
    "    out=Conv2D(filters=1, kernel_size=2, strides=1)(inp)\n",
    "#     print(out.shape)\n",
    "    out=BatchNormalization()(out)\n",
    "    out=LeakyReLU('0.05')(out)\n",
    "#     out=Activation('relu')(out)\n",
    "    # out=MaxPooling2D(pool_size=(3, 3), strides=2)(out)\n",
    "    # print(out.shape)\n",
    "    out=AveragePooling2D()(out)\n",
    "#     out=GlobalAveragePooling2D()(out)\n",
    "    out=Flatten()(out)\n",
    "    out=Dense(traffic_n)(out)\n",
    "    tra=Model(inputs=inp, outputs=out)\n",
    "    \n",
    "#     特征组件\n",
    "    sentence_input = Input(shape=(54+traffic_n,))\n",
    "    # s_input=keras.layers.concatenate([sentence_input])\n",
    "    embed = Reshape((54+traffic_n,1))(sentence_input)\n",
    "    l_lstm=Attention(3,16)([embed,embed,embed])\n",
    "#     l_lstm = Bidirectional(GRU(32, return_sequences=True))(embed)\n",
    "#     embed = Reshape((54+traffic_n,1))(l_lstm)\n",
    "    l_dense = TimeDistributed(Dense(32))(l_lstm)\n",
    "    l_att = AttentionLayer()(l_dense)\n",
    "\n",
    "    sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "    \n",
    "    review_input = Input(shape=(MAX_SENTS,54))\n",
    "    r_input = Input(shape=(MAX_SENTS,16, 16, 3))\n",
    "    r_encoder = TimeDistributed(tra)(r_input)\n",
    "    s_input=keras.layers.concatenate([r_encoder,review_input])\n",
    "    \n",
    "    review_encoder = TimeDistributed(sentEncoder)(s_input)\n",
    "    \n",
    "    time_input=Input(shape=(MAX_SENTS,3))\n",
    "    t_encoder = TimeDistributed(tm)(time_input)\n",
    "\n",
    "    w_input=Input(shape=(MAX_SENTS,3))\n",
    "    w_encoder = TimeDistributed(wm)(w_input)\n",
    "\n",
    "    wea_input=Input(shape=(MAX_SENTS,5))\n",
    "    wea_encoder = TimeDistributed(weam)(wea_input)\n",
    "#     we_time_encoder=keras.layers.concatenate([wea_input,review_encoder])\n",
    "#     we_time_encoder=keras.layers.concatenate([t_encoder,w_encoder,wea_input,review_encoder])\n",
    "\n",
    "#     l_lstm_sent = Bidirectional(GRU(50, return_sequences=True))(we_time_encoder)\n",
    "\n",
    "#     l_lstm_sent = Bidirectional(GRU(32, return_sequences=True))(review_encoder)\n",
    "    l_lstm_sent=TCN(padding='same',return_sequences=True)(review_encoder)\n",
    "    we_time_encoder=keras.layers.concatenate([t_encoder,w_encoder,wea_input,l_lstm_sent])\n",
    "\n",
    "    l_dense_sent = TimeDistributed(Dense(64))(we_time_encoder)\n",
    "#     l_dense_sent = TCN(padding='same',return_sequences=True)(we_time_encoder)\n",
    "#     l_att_sent = AttentionLayer()(l_dense_sent)\n",
    "#     l_dense_sent1 = Lambda(lambda x: K.permute_dimensions(x, (0, 2, 1)))(l_dense_sent)\n",
    "#     l_dense_sent2=Activation('tanh')(l_dense_sent1)\n",
    "#     l_dense_sent3=Activation('relu')(l_dense_sent2)\n",
    "    \n",
    "# #     a = K.permute_dimensions(a, (0, 2, 1))\n",
    "#     l_dense_sent4 = Lambda(lambda x: K.permute_dimensions(x, (0, 2, 1)))(l_dense_sent3)\n",
    "#     l_att_sent1 = Dot(axes=1)([l_dense_sent4 ,l_dense_sent])\n",
    "# #     outputs2 = K.sum(outputs1, axis=1)\n",
    "#     l_att_sent = Lambda(lambda x: K.sum(x, axis=1))(l_att_sent1)    \n",
    "    \n",
    "    \n",
    "#     l_dense_sent = Bidirectional(GRU(32, return_sequences=True))(we_time_encoder)\n",
    "\n",
    "    \n",
    "#     l_dense_sent = TimeDistributed(Dense(64))(we_time_encoder)\n",
    "    l_att_sent = AttentionLayer()(l_dense_sent)\n",
    "    preds = Dense(futrue_time)(l_att_sent)\n",
    "    model_1 = Model([time_input,w_input,wea_input,r_input,review_input], preds)\n",
    "    model_1.compile(optimizer=Adam(lr=learn_rate, beta_1=0.99, beta_2=0.999, decay=0.0006),\n",
    "                        loss='mae')\n",
    "    return model_1\n",
    "\n",
    "model=create_model()\n",
    "history=model.fit([time_m,w_m,wea_m,ge_m,sd_m],td, epochs=80, batch_size=128,verbose=2,validation_split=0.2,shuffle=True)\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           (None, 24, 16, 16, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, 24, 3)        167         input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 24, 54)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 24, 57)       0           time_distributed_36[0][0]        \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 24, 32)       3313        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 24, 64)       2112        time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 24, 64)       8256        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 24, 64)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 24, 64)       0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 24, 64)       0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 24, 64)       0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 24, 64)       8256        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 24, 64)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 24, 64)       0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 24, 64)       0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 24, 64)       0           add_18[0][0]                     \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 24, 64)       8256        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 24, 64)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 24, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 24, 64)       0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 24, 64)       0           add_19[0][0]                     \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 24, 64)       8256        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 24, 64)       0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 24, 64)       0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 24, 64)       0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 24, 64)       0           add_20[0][0]                     \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 24, 64)       8256        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 64)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 24, 64)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 24, 64)       0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 24, 64)       0           add_21[0][0]                     \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 24, 64)       8256        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 24, 64)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 24, 64)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 24, 64)       0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_61 (InputLayer)           (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 24, 64)       0           conv1d_16[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, 24, 9)        108         input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, 24, 6)        60          input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           (None, 24, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 64)       0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 24, 84)       0           time_distributed_38[0][0]        \n",
      "                                                                 time_distributed_39[0][0]        \n",
      "                                                                 input_62[0][0]                   \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 24, 64)       5440        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_9 (AttentionLay (None, 64)           576         time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 24)           1560        attention_layer_9[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 87,832\n",
      "Trainable params: 87,800\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.37 28.404\n"
     ]
    }
   ],
   "source": [
    "pre_test=model.predict([time_m_test,w_m_test,wea_m_test,ge_m_test,sd_m_test])\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.round(mean_absolute_error(pre_test,td_test[:145]),3),np.round(np.sqrt(mean_squared_error(pre_test,td_test[:145])),3))\n",
    "# mean_absolute_error(pre_test,td_test[:145]),np.sqrt(mean_squared_error(pre_test,td_test[:145]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = K.function(model.inputs, [model.get_layer('dense_21').get_output_at(0) for t in range(24)])\n",
    "# f = K.function(model.inputs, [model.get_layer('attention_weights3').output])\n",
    "\n",
    "f = K.function(model.inputs, [model.get_layer('concatenate_12').output])\n",
    "\n",
    "t=22\n",
    "\n",
    "# r = f([time_m_test[1].reshape(1,24,3),w_m_test[1].reshape(1,24,3),wea_m_test[1].reshape(1,24,5),ge_m_test[1].reshape(1,24,16,16,3),sd_m_test[1].reshape(1,24,55)])\n",
    "\n",
    "r = f([time_m_test[t].reshape(1,24,3),w_m_test[t].reshape(1,24,3),wea_m_test[t].reshape(1,24,5),ge_m_test[t].reshape(1,24,16,16,3),sd_m_test[t].reshape(1,24,54)])\n",
    "\n",
    "# r = f([time_m,w_m,wea_m,ge_m,sd_m])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.37847602e+00,  -1.62427771e+00,  -1.61899745e-01,\n",
       "         6.37987435e-01,  -6.61020935e-01,  -2.04407930e-01,\n",
       "        -1.85956669e+00,   3.45580399e-01,  -2.74696779e+00,\n",
       "         4.00273353e-01,  -3.41444850e+00,  -2.31879890e-01,\n",
       "        -1.75404072e-01,   8.70081365e-01,  -4.36676979e-01,\n",
       "         1.20118104e-01,   1.00378025e+00,  -1.24483192e+00,\n",
       "        -3.54080200e-01,   2.27805638e+00,   6.55511618e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.33255935e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.40505600e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.71358180e+00,\n",
       "         5.67757070e-01,   5.94041169e-01,   0.00000000e+00,\n",
       "         3.83861160e+00,   1.54779601e+00,   3.22102547e+00,\n",
       "         0.00000000e+00,   4.82361794e-01,   6.08873558e+00,\n",
       "         3.98583031e+00,   5.26108789e+00,   0.00000000e+00,\n",
       "         1.51906323e+00,   7.56980419e-01,   7.99039721e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.17572784e+00,   0.00000000e+00,\n",
       "         3.02051544e+00,   0.00000000e+00,   4.70520306e+00,\n",
       "         3.50224710e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.26856792e-01,\n",
       "         0.00000000e+00,   3.16233397e+00,   3.72529030e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.23879576e+00,\n",
       "         1.70400763e+00,   0.00000000e+00,   1.80799782e-01,\n",
       "         0.00000000e+00,   7.61847258e-01,   1.57619512e+00,\n",
       "         7.52310514e-01,   3.06401253e+00,   2.23511457e+00,\n",
       "         2.44680119e+00,   1.52405238e+00,   5.63370109e-01,\n",
       "         0.00000000e+00,   1.50809395e+00,   0.00000000e+00,\n",
       "         1.93983778e-01,   0.00000000e+00,   1.02446151e+00], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"lrp.z\", model, allow_lambda_layers = True)\n",
    "analyzer = innvestigate.create_analyzer(\"lrp.z\", model, allow_lambda_layers = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem=sd_m[0].reshape(1,24,54)\n",
    "tem1=ge_m[0].reshape(1,24, 16, 16, 3)\n",
    "tem2=time_m[0].reshape(1,24, 3)\n",
    "tem3=w_m[0].reshape(1,24, 3)\n",
    "tem4=wea_m[0].reshape(1,24,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_keras_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-787cc8229a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtem2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtem3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtem4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtem1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36manalyze\u001b[1;34m(self, X, neuron_selection)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \"\"\"\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_analyzer_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_analyzer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36mcreate_analyzer_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         tmp = self._create_analysis(\n\u001b[1;32m--> 411\u001b[1;33m             model, stop_analysis_at_tensors=stop_analysis_at_tensors)\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_analyzer.py\u001b[0m in \u001b[0;36m_create_analysis\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# FINALIZED constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLRP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m_create_analysis\u001b[1;34m(self, model, stop_analysis_at_tensors)\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             return_all_reversed_tensors=return_all_reversed_tensors)\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_all_reversed_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m_reverse_model\u001b[1;34m(self, model, stop_analysis_at_tensors, return_all_reversed_tensors)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mclip_all_reversed_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reverse_clip_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[0mproject_bottleneck_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reverse_project_bottleneck_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m             return_all_reversed_tensors=return_all_reversed_tensors)\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\utils\\keras\\graph.py\u001b[0m in \u001b[0;36mreverse_model\u001b[1;34m(model, reverse_mappings, default_reverse_mapping, head_mapping, stop_mapping_at_tensors, verbose, return_all_reversed_tensors, clip_all_reversed_tensors, project_bottleneck_tensors, execution_trace, reapply_on_copied_layers)\u001b[0m\n\u001b[0;32m   1024\u001b[0m                     \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m                     \u001b[1;34m\"layer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m                     \u001b[1;34m\"stop_mapping_at_tensors\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlocal_stop_mapping_at_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m                 })\n\u001b[0;32m   1028\u001b[0m             \u001b[0mreversed_Xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreversed_Xs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_analyzer.py\u001b[0m in \u001b[0;36m_default_reverse_mapping\u001b[1;34m(self, Xs, Ys, reversed_Ys, reverse_state)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;31m##print('ilayers.GradientWRT')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m             return self._gradient_reverse_mapping(\n\u001b[1;32m--> 477\u001b[1;33m                 Xs, Ys, reversed_Ys, reverse_state)\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;31m########################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m_gradient_reverse_mapping\u001b[1;34m(self, Xs, Ys, reversed_Ys, reverse_state)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_gradient_reverse_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreversed_Ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreverse_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stop_mapping_at_tensors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0milayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientWRT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mreversed_Ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reverse_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m                                    \u001b[0minput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m                                    arguments=user_kwargs)\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;31m# Apply activity regularizer if any:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[1;34m(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments)\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;31m# Update tensor history, _keras_shape and _uses_learning_phase.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m             uses_lp = any(\n\u001b[0;32m    567\u001b[0m                 [getattr(x, '_uses_learning_phase', False)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_keras_shape'"
     ]
    }
   ],
   "source": [
    "analysis = analyzer.analyze([tem2,tem3,tem4,tem1,tem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=analysis[0]\n",
    "a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "a /= np.max(np.abs(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 5)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49735832, -0.5265522 , -0.52103627, -0.51862955, -0.52315205,\n",
       "        -0.51850593, -0.51739514, -0.51968604,  0.98840296,  0.9996708 ,\n",
       "         0.99372292,  0.99956232, -0.51374751,  0.99716723,  0.99405044,\n",
       "         0.99603361, -0.50925744, -0.51431334, -0.512025  , -0.51035821,\n",
       "        -0.50560743, -0.50662416, -0.50433177,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from heatmap import html_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce87dd438>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a0=analysis[0]\n",
    "a0 = a0.sum(axis=np.argmax(np.asarray(a0.shape) == 3))\n",
    "a0 /= np.max(np.abs(a0))\n",
    "plt.imshow(a0, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce882a0b8>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1=analysis[1]\n",
    "a1 = a1.sum(axis=np.argmax(np.asarray(a1.shape) == 3))\n",
    "a1 /= np.max(np.abs(a1))\n",
    "plt.imshow(a1, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ce88c6978>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a2=analysis[2]\n",
    "a2 = a2.sum(axis=np.argmax(np.asarray(a2.shape) == 3))\n",
    "a2 /= np.max(np.abs(a2))\n",
    "plt.imshow(a2, cmap=\"seismic\", clim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3=analysis[3]\n",
    "a3 = a3.sum(axis=np.argmax(np.asarray(a3.shape) == 3))\n",
    "a3 /= np.max(np.abs(a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a3=analysis[3]\n",
    "# a3 = a3.sum(axis=np.argmax(np.asarray(a3.shape) == 3))\n",
    "# a3 /= np.max(np.abs(a3))\n",
    "# plt.imshow(a2, cmap=\"seismic\", clim=(-1, 1))\n",
    "for i in range(24):\n",
    "    plt.imshow(a3[0][i], cmap=\"seismic\", clim=(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#8e8eff\">0</span> <span style=\"background-color:#bebeff\">1</span> <span style=\"background-color:#7070ff\">2</span> <span style=\"background-color:#8888ff\">3</span> <span style=\"background-color:#5151ff\">4</span> <span style=\"background-color:#f6f6ff\">5</span> <span style=\"background-color:#d0d0ff\">6</span> <span style=\"background-color:#9a9aff\">7</span> <span style=\"background-color:#a3a3ff\">8</span> <span style=\"background-color:#b0b0ff\">9</span> <span style=\"background-color:#c2c2ff\">10</span> <span style=\"background-color:#9a9aff\">11</span> <span style=\"background-color:#bcbcff\">12</span> <span style=\"background-color:#6969ff\">13</span> <span style=\"background-color:#ffe2e2\">14</span> <span style=\"background-color:#ff5050\">15</span> <span style=\"background-color:#b0b0ff\">16</span> <span style=\"background-color:#f6f6ff\">17</span> <span style=\"background-color:#ff3636\">18</span> <span style=\"background-color:#ff7c7c\">19</span> <span style=\"background-color:#ff9c9c\">20</span> <span style=\"background-color:#ffb6b6\">21</span> <span style=\"background-color:#ff6666\">22</span> <span style=\"background-color:#fffafa\">23</span> <span style=\"background-color:#ffd3d3\">24</span> <span style=\"background-color:#ff9090\">25</span> <span style=\"background-color:#ffb8b8\">26</span> <span style=\"background-color:#ff2c2c\">27</span> <span style=\"background-color:#ff4444\">28</span> <span style=\"background-color:#a0a0ff\">29</span> <span style=\"background-color:#ff9e9e\">30</span> <span style=\"background-color:#dedeff\">31</span> <span style=\"background-color:#ffaaaa\">32</span> <span style=\"background-color:#fcfcff\">33</span> <span style=\"background-color:#ceceff\">34</span> <span style=\"background-color:#ff9a9a\">35</span> <span style=\"background-color:#ff9c9c\">36</span> <span style=\"background-color:#ffe2e2\">37</span> <span style=\"background-color:#ff7474\">38</span> <span style=\"background-color:#ff8e8e\">39</span> <span style=\"background-color:#ff0c0c\">40</span> <span style=\"background-color:#ff9090\">41</span> <span style=\"background-color:#ff8080\">42</span> <span style=\"background-color:#ff9696\">43</span> <span style=\"background-color:#ff8383\">44</span> <span style=\"background-color:#ff6161\">45</span> <span style=\"background-color:#ffa6a6\">46</span> <span style=\"background-color:#e2e2ff\">47</span> <span style=\"background-color:#ffacac\">48</span> <span style=\"background-color:#8c8cff\">49</span> <span style=\"background-color:#ff4e4e\">50</span> <span style=\"background-color:#ff3030\">51</span> <span style=\"background-color:#ff0000\">52</span> <span style=\"background-color:#fff4f4\">53</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a4=analysis[4]\n",
    "a4 = a4.sum(axis=np.argmax(np.asarray(a4.shape) == 3))\n",
    "a4 /= np.max(np.abs(a4))\n",
    "plt.imshow(a4, cmap=\"seismic\", clim=(-1, 1))\n",
    "\n",
    "\n",
    "display(HTML(html_heatmap([str(i) for i in range(54)], a4[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Convolution1D, Dense\n",
    "from keras.models import Input, Model\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def channel_normalization(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\" Normalize a layer to the maximum activation\n",
    "\n",
    "    This keeps a layers values between zero and one.\n",
    "    It helps with relu's unbounded activation\n",
    "\n",
    "    Args:\n",
    "        x: The layer to normalize\n",
    "\n",
    "    Returns:\n",
    "        A maximal normalized layer\n",
    "    \"\"\"\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "\n",
    "def wave_net_activation(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\"This method defines the activation used for WaveNet\n",
    "\n",
    "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
    "\n",
    "    Args:\n",
    "        x: The layer we want to apply the activation to\n",
    "\n",
    "    Returns:\n",
    "        A new layer with the wavenet activation applied\n",
    "    \"\"\"\n",
    "    tanh_out = Activation('tanh')(x)\n",
    "    sigm_out = Activation('sigmoid')(x)\n",
    "    return keras.layers.multiply([tanh_out, sigm_out])\n",
    "\n",
    "\n",
    "def residual_block(x, s, i, c, activation, nb_filters, kernel_size, padding, dropout_rate=0):\n",
    "    # type: (Layer, int, int, int, str, int, int, str, float, str) -> Tuple[Layer, Layer]\n",
    "    \"\"\"Defines the residual block for the WaveNet TCN\n",
    "\n",
    "    Args:\n",
    "        x: The previous layer in the model\n",
    "        s: The stack index i.e. which stack in the overall TCN\n",
    "        i: The dilation power of 2 we are using for this residual block\n",
    "        c: The dilation name to make it unique. In case we have same dilation twice: [1, 1, 2, 4].\n",
    "        activation: The name of the type of activation to use\n",
    "        nb_filters: The number of convolutional filters to use in this block\n",
    "        kernel_size: The size of the convolutional kernel\n",
    "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A tuple where the first element is the residual model layer, and the second\n",
    "        is the skip connection.\n",
    "    \"\"\"\n",
    "\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding=padding)(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "    elif activation == 'wavenet':\n",
    "        x = wave_net_activation(conv)\n",
    "    else:\n",
    "        x = Activation(activation)(conv)\n",
    "\n",
    "    x = SpatialDropout1D(dropout_rate)(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = keras.layers.add([original_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        # print(f'Updated dilations from {dilations} to {new_dilations} because of backwards compatibility.')\n",
    "        return new_dilations\n",
    "\n",
    "\n",
    "class TCN:\n",
    "    \"\"\"Creates a TCN layer.\n",
    "\n",
    "        Input shape:\n",
    "            A tensor of shape (batch_size, timesteps, input_dim).\n",
    "\n",
    "        Args:\n",
    "            nb_filters: The number of filters to use in the convolutional layers.\n",
    "            kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "            dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "            nb_stacks : The number of stacks of residual blocks to use.\n",
    "            activation: The activations to use (norm_relu, wavenet, relu...).\n",
    "            padding: The padding to use in the convolutional layers, 'causal' or 'same'.\n",
    "            use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "            return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "            name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "        Returns:\n",
    "            A TCN layer.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=[1, 2, 4, 8, 16, 32],\n",
    "                 activation='norm_relu',\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.0,\n",
    "                 return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.activation = activation\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding != 'causal' and padding != 'same':\n",
    "            raise ValueError(\"Only 'causal' or 'same' padding are compatible for this layer.\")\n",
    "\n",
    "        if not isinstance(nb_filters, int):\n",
    "            print('An interface change occurred after the version 2.1.2.')\n",
    "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
    "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
    "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
    "            raise Exception()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        x = Convolution1D(self.nb_filters, 1, padding=self.padding)(x)\n",
    "        skip_connections = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for i, d in enumerate(self.dilations):\n",
    "                x, skip_out = residual_block(x, s, d, i, self.activation, self.nb_filters,\n",
    "                                             self.kernel_size, self.padding, self.dropout_rate)\n",
    "                skip_connections.append(skip_out)\n",
    "        if self.use_skip_connections:\n",
    "            x = keras.layers.add(skip_connections)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        if not self.return_sequences:\n",
    "            output_slice_index = -1\n",
    "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def compiled_tcn(num_feat,  # type: int\n",
    "                 num_classes,  # type: int\n",
    "                 nb_filters,  # type: int\n",
    "                 kernel_size,  # type: int\n",
    "                 dilations,  # type: List[int]\n",
    "                 nb_stacks,  # type: int\n",
    "                 max_len,  # type: int\n",
    "                 activation='norm_relu',  # type: str\n",
    "                 padding='causal',  # type: str\n",
    "                 use_skip_connections=True,  # type: bool\n",
    "                 return_sequences=True,\n",
    "                 regression=False,  # type: bool\n",
    "                 dropout_rate=0.05,  # type: float\n",
    "                 ):\n",
    "    # type: (...) -> keras.Model\n",
    "    \"\"\"Creates a compiled TCN model for a given task (i.e. regression or classification).\n",
    "\n",
    "    Args:\n",
    "        num_feat: The number of features of your input, i.e. the last dimension of: (batch_size, timesteps, input_dim).\n",
    "        num_classes: The size of the final dense layer, how many classes we are predicting.\n",
    "        nb_filters: The number of filters to use in the convolutional layers.\n",
    "        kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "        dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "        nb_stacks : The number of stacks of residual blocks to use.\n",
    "        max_len: The maximum sequence length, use None if the sequence length is dynamic.\n",
    "        activation: The activations to use.\n",
    "        padding: The padding to use in the convolutional layers.\n",
    "        use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "        return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "        regression: Whether the output should be continuous or discrete.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A compiled keras TCN.\n",
    "    \"\"\"\n",
    "\n",
    "    dilations = process_dilations(dilations)\n",
    "\n",
    "    input_layer = Input(shape=(max_len, num_feat))\n",
    "\n",
    "    x = TCN(nb_filters, kernel_size, nb_stacks, dilations, activation,\n",
    "            padding, use_skip_connections, dropout_rate, return_sequences)(input_layer)\n",
    "\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "    if not regression:\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO To remove later.\n",
    "        def accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            if K.ndim(y_true) == K.ndim(y_pred):\n",
    "                y_true = K.squeeze(y_true, -1)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "            y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n",
    "        print('Adam with norm clipping.')\n",
    "    else:\n",
    "        # regression\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('linear')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='mean_squared_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
