{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, GRU, Multiply, Reshape\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "# from tcn import TCN\n",
    "%matplotlib inline\n",
    "from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   \n",
    "from keras.models import Model \n",
    "from keras.layers import Conv2D\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, GlobalAveragePooling2D,AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "MAX_SENT_LENGTH = 55\n",
    "MAX_SENTS = 24\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn import preprocessing\n",
    "from pandas import concat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#matplotlib inline\n",
    "#参数初始化\n",
    "discfile = '../data/data_wea_time_unify.csv'\n",
    "\n",
    "data = pd.read_csv(discfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "futrue_time=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(24,96):\n",
    "    data['PM25_m'+str(i)]=data['PM25_mean'].shift(-i)\n",
    "data=data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'date', 'hour', 'PM25_1', 'PM25_2',\n",
       "       'PM25_3', 'PM25_4', 'PM25_5', 'PM25_6',\n",
       "       ...\n",
       "       'PM25_m86', 'PM25_m87', 'PM25_m88', 'PM25_m89', 'PM25_m90', 'PM25_m91',\n",
       "       'PM25_m92', 'PM25_m93', 'PM25_m94', 'PM25_m95'],\n",
       "      dtype='object', length=148)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_data=data.iloc[:,76:]\n",
    "source_data=data.iloc[:,4:58]\n",
    "\n",
    "import copy\n",
    "sd=copy.deepcopy(source_data)\n",
    "td=copy.deepcopy(target_data)\n",
    "\n",
    "td=td.dropna(how='any')\n",
    "sd=sd.values\n",
    "td=td.values\n",
    "td_test=td[5801:,:futrue_time]   \n",
    "td=td[:5801,:futrue_time]\n",
    "sd_m=[]\n",
    "for i in range(1,MAX_SENTS+1):\n",
    "    locals()['sd'+str(i)]=sd[i-1:5800+i]\n",
    "\n",
    "    sd_m.append(locals()['sd'+str(i)])\n",
    "sd_m=(np.array(sd_m).swapaxes(0,1))\n",
    "\n",
    "\n",
    "######test\n",
    "sd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['sd_t'+str(i)]=sd[5800+i:5969-24+i]\n",
    "    \n",
    "    sd_m_test.append(locals()['sd_t'+str(i)])\n",
    "\n",
    "sd_m_test=(np.array(sd_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wea_data=data.iloc[:,67:75]\n",
    "\n",
    "w=wea_data[['Conditions','Wind Dir','Quality evaluation']]\n",
    "\n",
    "w_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w'+str(i)]=w[i-1:5800+i].values\n",
    "    \n",
    "    w_m.append(locals()['w'+str(i)])\n",
    "    \n",
    "wea=wea_data[['Dew Point','Humidity','Pressure','Temp.','Wind Speed']]\n",
    "wea_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea'+str(i)]=wea[i-1:5800+i].values\n",
    "    \n",
    "    wea_m.append(locals()['wea'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data=data.iloc[:,64:67]\n",
    "\n",
    "time_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time'+str(i)]=time_data[i-1:5800+i].values\n",
    "    \n",
    "    time_m.append(locals()['time'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m=(np.array(time_m).swapaxes(0,1))\n",
    "w_m=(np.array(w_m).swapaxes(0,1))\n",
    "wea_m=(np.array(wea_m).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['time_t'+str(i)]=time_data[5800+i:5969-24+i].values\n",
    "    \n",
    "    time_m_test.append(locals()['time_t'+str(i)])\n",
    "\n",
    "time_m_test=(np.array(time_m_test).swapaxes(0,1))\n",
    "\n",
    "w_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['w_t'+str(i)]=w[5800+i:5969-24+i].values\n",
    "    \n",
    "    w_m_test.append(locals()['w_t'+str(i)])\n",
    "\n",
    "w_m_test=(np.array(w_m_test).swapaxes(0,1))\n",
    "\n",
    "wea_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['wea_t'+str(i)]=wea[5800+i:5969-24+i].values\n",
    "    \n",
    "    wea_m_test.append(locals()['wea_t'+str(i)])\n",
    "\n",
    "wea_m_test=(np.array(wea_m_test).swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交通数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "ground = h5py.File('../data/inte_g_12.h5', 'r')\n",
    "g = ground['X']\n",
    "\n",
    "ele_zs = h5py.File('../data/inte_e_zs_12_new.h5', 'r')\n",
    "ezs = ele_zs['X']\n",
    "\n",
    "ele_sd = h5py.File('../data/inte_e_sd_12_new.h5', 'r')\n",
    "esd = ele_sd['X']\n",
    "\n",
    "g_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g'+str(i)]=g[i-1:5800+i]\n",
    "    \n",
    "    g_m.append(locals()['g'+str(i)])\n",
    "g_m=(np.array(g_m).swapaxes(0,1))\n",
    "g_m=g_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ezs_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs'+str(i)]=ezs[i-1:5800+i]\n",
    "    \n",
    "    ezs_m.append(locals()['ezs'+str(i)])\n",
    "ezs_m=(np.array(ezs_m).swapaxes(0,1))\n",
    "\n",
    "ezs_m=ezs_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "esd_m=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd'+str(i)]=esd[i-1:5800+i]\n",
    "    \n",
    "    esd_m.append(locals()['esd'+str(i)])\n",
    "esd_m=(np.array(esd_m).swapaxes(0,1))\n",
    "\n",
    "esd_m=esd_m.reshape(5801, 24, 16,16,1)\n",
    "\n",
    "ge_m=[ezs_m,esd_m,g_m]\n",
    "\n",
    "ge_m=np.array(ge_m).reshape(5801, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####test\n",
    "g_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['g_t'+str(i)]=g[5800+i:5969-24+i]\n",
    "    \n",
    "    g_m_test.append(locals()['g_t'+str(i)])\n",
    "g_m_test=(np.array(g_m_test).swapaxes(0,1))\n",
    "\n",
    "g_m_test=g_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "ezs_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['ezs_t'+str(i)]=ezs[5800+i:5969-24+i]\n",
    "    \n",
    "    ezs_m_test.append(locals()['ezs_t'+str(i)])\n",
    "ezs_m_test=(np.array(ezs_m_test).swapaxes(0,1))\n",
    "\n",
    "ezs_m_test=ezs_m_test.reshape(145, 24, 16,16,1)\n",
    "\n",
    "esd_m_test=[]\n",
    "for i in range(1,25):\n",
    "    locals()['esd_t'+str(i)]=esd[5800+i:5969-24+i]\n",
    "    \n",
    "    esd_m_test.append(locals()['esd_t'+str(i)])\n",
    "esd_m_test=(np.array(esd_m_test).swapaxes(0,1))\n",
    "\n",
    "esd_m_test=esd_m_test.reshape(145, 24, 16,16,1)\n",
    "ge_m_test=[ezs_m_test,esd_m_test,g_m_test]\n",
    "\n",
    "ge_m_test=np.array(ge_m_test).reshape(145, 24, 16,16,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义softmax函数\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"\n",
    "    Softmax activation function.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! -*- coding: utf-8 -*-\n",
    "T = 24  #时间序列长度\n",
    "n = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局网络层对象\n",
    "repeator = RepeatVector((sd).shape[1])\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_tanh1 = Dense(8, activation = \"tanh\")\n",
    "densor_tanh2 = Dense(8, activation = \"tanh\")\n",
    "densor_tanh3 = Dense(8, activation = \"tanh\")\n",
    "densor_relu1 = Dense(1, activation = \"relu\")\n",
    "densor_relu2 = Dense(1, activation = \"relu\")\n",
    "densor_relu3 = Dense(1, activation = \"relu\")\n",
    "activator1 = Activation(softmax, name='attention_weights1')\n",
    "activator2 = Activation(softmax, name='attention_weights2')\n",
    "activator3 = Activation(softmax, name='attention_weights3')\n",
    "dotor = Dot(axes = 1)\n",
    "def one_step_attention1(a):\n",
    "    # 将s_prev复制Tx次\n",
    "#     s_prev = repeator(s_prev)\n",
    "    # 拼接BiRNN隐层状态与s_prev\n",
    "#     concat = concatenator([a, s_prev])\n",
    "    # 计算energies\n",
    "    e = densor_tanh1(a)\n",
    "    energies = densor_relu1(e)\n",
    "    # 计算weights\n",
    "    alphas = activator1(energies)\n",
    "    # 加权得到Context Vector\n",
    "#     context = dotor([alphas, a])\n",
    "    \n",
    "    return alphas\n",
    "def one_step_attention2(a):\n",
    "    \"\"\"\n",
    "    Attention机制的实现，返回加权后的Context Vector\n",
    "    \n",
    "    @param a: BiRNN的隐层状态\n",
    "    @param s_prev: Decoder端LSTM的上一轮隐层输出\n",
    "    \n",
    "    Returns:\n",
    "    context: 加权后的Context Vector\n",
    "    \"\"\"\n",
    "    # 计算energies\n",
    "    e = densor_tanh2(a)\n",
    "    energies = densor_relu2(e)\n",
    "    # 计算weights\n",
    "    alphas = activator2(energies)\n",
    "    # 加权得到Context Vector\n",
    "#     context = dotor([alphas, a])\n",
    "    return alphas\n",
    "\n",
    "def one_step_attention3(a):\n",
    "    \"\"\"\n",
    "    Attention机制的实现，返回加权后的Context Vector\n",
    "    \n",
    "    @param a: BiRNN的隐层状态\n",
    "    @param s_prev: Decoder端LSTM的上一轮隐层输出\n",
    "    \n",
    "    Returns:\n",
    "    context: 加权后的Context Vector\n",
    "    \"\"\"\n",
    "    # 计算energies\n",
    "    e = densor_tanh3(a)\n",
    "    energies = densor_relu3(e)\n",
    "    # 计算weights\n",
    "    alphas = activator3(energies)\n",
    "    # 加权得到Context Vector\n",
    "#     context = dotor([alphas, a])\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4640 samples, validate on 1161 samples\n",
      "Epoch 1/120\n",
      " - 144s - loss: 113.7572 - val_loss: 92.3846\n",
      "Epoch 2/120\n",
      " - 91s - loss: 81.9389 - val_loss: 66.3461\n",
      "Epoch 3/120\n",
      " - 91s - loss: 61.8131 - val_loss: 50.3098\n",
      "Epoch 4/120\n",
      " - 90s - loss: 47.7294 - val_loss: 38.2768\n",
      "Epoch 5/120\n",
      " - 89s - loss: 39.5544 - val_loss: 33.5040\n",
      "Epoch 6/120\n",
      " - 89s - loss: 36.9598 - val_loss: 31.6261\n",
      "Epoch 7/120\n",
      " - 90s - loss: 35.3006 - val_loss: 30.0605\n",
      "Epoch 8/120\n",
      " - 91s - loss: 34.0765 - val_loss: 29.3828\n",
      "Epoch 9/120\n",
      " - 92s - loss: 33.3347 - val_loss: 28.7819\n",
      "Epoch 10/120\n",
      " - 91s - loss: 32.5325 - val_loss: 28.0737\n",
      "Epoch 11/120\n",
      " - 101s - loss: 31.8090 - val_loss: 27.6206\n",
      "Epoch 12/120\n",
      " - 96s - loss: 31.3544 - val_loss: 27.3757\n",
      "Epoch 13/120\n",
      " - 92s - loss: 30.9882 - val_loss: 27.0703\n",
      "Epoch 14/120\n",
      " - 91s - loss: 30.6496 - val_loss: 26.8374\n",
      "Epoch 15/120\n",
      " - 90s - loss: 30.4616 - val_loss: 26.7572\n",
      "Epoch 16/120\n",
      " - 90s - loss: 30.3549 - val_loss: 26.7091\n",
      "Epoch 17/120\n",
      " - 91s - loss: 30.2479 - val_loss: 26.6320\n",
      "Epoch 18/120\n",
      " - 90s - loss: 30.1120 - val_loss: 26.5512\n",
      "Epoch 19/120\n",
      " - 89s - loss: 29.9871 - val_loss: 26.5017\n",
      "Epoch 20/120\n",
      " - 89s - loss: 29.8897 - val_loss: 26.4862\n",
      "Epoch 21/120\n",
      " - 90s - loss: 29.8011 - val_loss: 26.4737\n",
      "Epoch 22/120\n",
      " - 89s - loss: 29.7103 - val_loss: 26.4492\n",
      "Epoch 23/120\n",
      " - 91s - loss: 29.6242 - val_loss: 26.4179\n",
      "Epoch 24/120\n",
      " - 89s - loss: 29.5396 - val_loss: 26.3767\n",
      "Epoch 25/120\n",
      " - 89s - loss: 29.4469 - val_loss: 26.3279\n",
      "Epoch 26/120\n",
      " - 89s - loss: 29.3418 - val_loss: 26.2804\n",
      "Epoch 27/120\n",
      " - 88s - loss: 29.2282 - val_loss: 26.2115\n",
      "Epoch 28/120\n",
      " - 89s - loss: 29.0885 - val_loss: 26.0797\n",
      "Epoch 29/120\n",
      " - 89s - loss: 28.8662 - val_loss: 25.9026\n",
      "Epoch 30/120\n",
      " - 90s - loss: 28.6149 - val_loss: 25.6268\n",
      "Epoch 31/120\n",
      " - 90s - loss: 28.3343 - val_loss: 25.3036\n",
      "Epoch 32/120\n",
      " - 90s - loss: 27.9537 - val_loss: 24.8332\n",
      "Epoch 33/120\n",
      " - 90s - loss: 27.4931 - val_loss: 24.4251\n",
      "Epoch 34/120\n",
      " - 89s - loss: 27.1665 - val_loss: 24.1259\n",
      "Epoch 35/120\n",
      " - 90s - loss: 26.8651 - val_loss: 23.8414\n",
      "Epoch 36/120\n",
      " - 89s - loss: 26.5851 - val_loss: 23.6286\n",
      "Epoch 37/120\n",
      " - 90s - loss: 26.3261 - val_loss: 23.2803\n",
      "Epoch 38/120\n",
      " - 90s - loss: 26.0850 - val_loss: 23.1891\n",
      "Epoch 39/120\n",
      " - 89s - loss: 25.8732 - val_loss: 23.0866\n",
      "Epoch 40/120\n",
      " - 90s - loss: 25.7140 - val_loss: 22.8337\n",
      "Epoch 41/120\n",
      " - 91s - loss: 25.5261 - val_loss: 22.6887\n",
      "Epoch 42/120\n",
      " - 94s - loss: 25.4022 - val_loss: 22.4936\n",
      "Epoch 43/120\n",
      " - 91s - loss: 25.2426 - val_loss: 22.5352\n",
      "Epoch 44/120\n",
      " - 92s - loss: 25.0878 - val_loss: 22.3372\n",
      "Epoch 45/120\n",
      " - 91s - loss: 24.9483 - val_loss: 22.5633\n",
      "Epoch 46/120\n",
      " - 90s - loss: 24.8182 - val_loss: 22.1346\n",
      "Epoch 47/120\n",
      " - 91s - loss: 24.6916 - val_loss: 22.3102\n",
      "Epoch 48/120\n",
      " - 92s - loss: 24.5744 - val_loss: 22.1258\n",
      "Epoch 49/120\n",
      " - 91s - loss: 24.4943 - val_loss: 22.0877\n",
      "Epoch 50/120\n",
      " - 91s - loss: 24.3874 - val_loss: 22.3486\n",
      "Epoch 51/120\n",
      " - 94s - loss: 24.2670 - val_loss: 22.0649\n",
      "Epoch 52/120\n",
      " - 90s - loss: 24.1876 - val_loss: 21.9547\n",
      "Epoch 53/120\n",
      " - 90s - loss: 24.0935 - val_loss: 22.1038\n",
      "Epoch 54/120\n",
      " - 90s - loss: 24.0151 - val_loss: 21.8849\n",
      "Epoch 55/120\n",
      " - 90s - loss: 23.9369 - val_loss: 22.0575\n",
      "Epoch 56/120\n",
      " - 91s - loss: 23.8579 - val_loss: 21.8725\n",
      "Epoch 57/120\n",
      " - 89s - loss: 23.7993 - val_loss: 21.8073\n",
      "Epoch 58/120\n",
      " - 91s - loss: 23.7423 - val_loss: 21.9992\n",
      "Epoch 59/120\n",
      " - 90s - loss: 23.7004 - val_loss: 21.9944\n",
      "Epoch 60/120\n",
      " - 90s - loss: 23.6296 - val_loss: 21.7634\n",
      "Epoch 61/120\n",
      " - 90s - loss: 23.5547 - val_loss: 21.5246\n",
      "Epoch 62/120\n",
      " - 90s - loss: 23.5041 - val_loss: 21.7013\n",
      "Epoch 63/120\n",
      " - 92s - loss: 23.4521 - val_loss: 21.4562\n",
      "Epoch 64/120\n",
      " - 92s - loss: 23.4033 - val_loss: 21.5931\n",
      "Epoch 65/120\n",
      " - 92s - loss: 23.3944 - val_loss: 21.5362\n",
      "Epoch 66/120\n",
      " - 92s - loss: 23.3136 - val_loss: 21.5375\n",
      "Epoch 67/120\n",
      " - 95s - loss: 23.2636 - val_loss: 21.5193\n",
      "Epoch 68/120\n",
      " - 91s - loss: 23.2140 - val_loss: 21.1635\n",
      "Epoch 69/120\n",
      " - 93s - loss: 23.1770 - val_loss: 21.5234\n",
      "Epoch 70/120\n",
      " - 92s - loss: 23.1279 - val_loss: 21.1538\n",
      "Epoch 71/120\n",
      " - 91s - loss: 23.0852 - val_loss: 21.2653\n",
      "Epoch 72/120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-f3d79c32aafe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwea_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mge_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msd_m\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;31m# 绘制训练 & 验证的损失值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model(learn_rate=0.001, neurons=24, traffic_n=3):\n",
    "#     时间戳模块    \n",
    "    inp_time=Input(shape=(3,))\n",
    "    embed_time1 = Embedding(24,3, input_length=3)(inp_time)\n",
    "#     embed_time = AttentionLayer()(embed_time)\n",
    "    embed_time2=Flatten()(embed_time1)\n",
    "    embed_time3=BatchNormalization()(embed_time2)\n",
    "    tm=Model(inputs=inp_time, outputs=embed_time3)\n",
    "    \n",
    "#     离散型气象数据模块\n",
    "    inp_w=Input(shape=(3,))\n",
    "    embed_w1 = Embedding(18, 2, input_length=3)(inp_w)\n",
    "#     embed_w = AttentionLayer()(embed_w)\n",
    "    embed_w2=Flatten()(embed_w1)\n",
    "    embed_w3=BatchNormalization()(embed_w2)\n",
    "    wm=Model(inputs=inp_w, outputs=embed_w3)\n",
    "    \n",
    "#     连续型气象数据模块\n",
    "    inp_we=Input(shape=(5,))\n",
    "#     embed_we = Reshape((5,1))(inp_we)\n",
    "    embed_we=BatchNormalization()(inp_we)\n",
    "#     embed_we = AttentionLayer()(embed_we)\n",
    "#     input_we_time=keras.layers.concatenate([embed_time,embed_w,embed_we])\n",
    "    weam=Model(inputs=inp_we, outputs=embed_we)\n",
    "    \n",
    "    \n",
    "#     交通指数数据模块\n",
    "    inp=Input(shape=(16, 16, 3))\n",
    "    out1=Conv2D(filters=1, kernel_size=2, strides=1)(inp)\n",
    "#     print(out.shape)\n",
    "    out2=BatchNormalization()(out1)\n",
    "    out3=Activation('relu')(out2)\n",
    "    # out=MaxPooling2D(pool_size=(3, 3), strides=2)(out)\n",
    "    # print(out.shape)\n",
    "    out4=AveragePooling2D()(out3)\n",
    "#     out=GlobalAveragePooling2D()(out)\n",
    "    out5=Flatten()(out4)\n",
    "#     print(out5.shape)\n",
    "    out6=Dense(traffic_n, activation='relu')(out5)\n",
    "    tra=Model(inputs=inp, outputs=out6)\n",
    "    \n",
    "    review_input = Input(shape=(MAX_SENTS,54))\n",
    "    r_input = Input(shape=(MAX_SENTS,16, 16, 3))\n",
    "    r_encoder = TimeDistributed(tra)(r_input)\n",
    "    s_input=keras.layers.concatenate([r_encoder,review_input])\n",
    "    \n",
    "    x = Lambda(lambda x: s_input[:,0,:])(s_input)\n",
    "    x = Reshape((54+traffic_n,1))(x)\n",
    "    l_lstm = Bidirectional(GRU(32, return_sequences=True))(x)\n",
    "#     l_dense = TimeDistributed(Dense(32))(l_lstm)\n",
    "#     l_att = AttentionLayer()(l_lstm)\n",
    "    l_att1 = one_step_attention1(l_lstm)\n",
    "    context = dotor([l_att1, l_lstm])\n",
    "    review_encoder = Reshape((-1,))(context)\n",
    "    \n",
    "    \n",
    "    for t in range(1,MAX_SENTS):\n",
    "        x = Lambda(lambda x: s_input[:,t,:])(s_input)\n",
    "        x = Reshape((54+traffic_n,1))(x)\n",
    "        l_lstm = Bidirectional(GRU(32, return_sequences=True))(x)\n",
    "#     l_dense = TimeDistributed(Dense(32))(l_lstm)\n",
    "#     l_att = AttentionLayer()(l_lstm)\n",
    "        l_att1 = one_step_attention1(l_lstm)\n",
    "        context = dotor([l_att1, l_lstm])\n",
    "        context = Reshape((-1,))(context)\n",
    "#         review_encoder.append(context)\n",
    "        review_encoder= Concatenate()([review_encoder,context])\n",
    "#     print(np.shape(review_encoder))    \n",
    "#     review_encoder=(np.array(review_encoder).swapaxes(0,1))\n",
    "    review_encoder=Reshape((MAX_SENTS,64))(review_encoder)\n",
    "    \n",
    "    \n",
    "    time_input=Input(shape=(MAX_SENTS,3))\n",
    "    t_encoder = TimeDistributed(tm)(time_input)\n",
    "\n",
    "    w_input=Input(shape=(MAX_SENTS,3))\n",
    "    w_encoder = TimeDistributed(wm)(w_input)\n",
    "\n",
    "    wea_input=Input(shape=(MAX_SENTS,5))\n",
    "    wea_encoder = TimeDistributed(weam)(wea_input)\n",
    "#     we_time_encoder=keras.layers.concatenate([wea_input,review_encoder])\n",
    "#     we_time_encoder=keras.layers.concatenate([t_encoder,w_encoder,wea_input,review_encoder])\n",
    "\n",
    "#     l_lstm_sent = Bidirectional(GRU(50, return_sequences=True))(we_time_encoder)\n",
    "\n",
    "    l_lstm_sent = Bidirectional(GRU(32, return_sequences=True))(review_encoder)\n",
    "#     l_lstm_sent=TCN(padding='same',return_sequences=True)(review_encoder)\n",
    "    we_time_encoder=keras.layers.concatenate([t_encoder,l_lstm_sent])\n",
    "# \n",
    "#     l_dense_sent = TimeDistributed(Dense(64))(we_time_encoder)\n",
    "#     l_dense_sent = TCN(padding='same',return_sequences=True)(we_time_encoder)\n",
    "    l_att = one_step_attention2(l_lstm_sent)\n",
    "    context1 = dotor([l_att, l_lstm_sent])\n",
    "    context2 = Reshape((-1,))(context1)\n",
    "    \n",
    "    we_encoder=keras.layers.concatenate([w_encoder,wea_input])\n",
    "    we_l_att = one_step_attention3(we_encoder)\n",
    "    we_context1 = dotor([we_l_att, we_encoder])\n",
    "    we_context2 = Reshape((-1,))(we_context1)\n",
    "    fin=keras.layers.concatenate([context2,we_context2])\n",
    "\n",
    "    preds = Dense(futrue_time)(fin)\n",
    "    model_1 = Model([time_input,w_input,wea_input,r_input,review_input], preds)\n",
    "    model_1.compile(optimizer=Adam(lr=learn_rate, beta_1=0.99, beta_2=0.999, decay=0.001),\n",
    "                        loss='mae')\n",
    "    return model_1\n",
    "\n",
    "model=create_model()\n",
    "history=model.fit([time_m,w_m,wea_m,ge_m,sd_m],td, epochs=120, batch_size=128,verbose=2,validation_split=0.2,shuffle=True)\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 24, 16, 16, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 24, 3)        167         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 24, 54)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 24, 57)       0           time_distributed_5[0][0]         \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_52 (Reshape)            (None, 57, 1)        0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 57, 1)        0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_26 (Bidirectional (None, 57, 64)       6528        reshape_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 57, 64)       6528        reshape_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 57, 1)        0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 57, 8)        520         bidirectional_26[0][0]           \n",
      "                                                                 bidirectional_27[0][0]           \n",
      "                                                                 bidirectional_28[0][0]           \n",
      "                                                                 bidirectional_29[0][0]           \n",
      "                                                                 bidirectional_30[0][0]           \n",
      "                                                                 bidirectional_31[0][0]           \n",
      "                                                                 bidirectional_32[0][0]           \n",
      "                                                                 bidirectional_33[0][0]           \n",
      "                                                                 bidirectional_34[0][0]           \n",
      "                                                                 bidirectional_35[0][0]           \n",
      "                                                                 bidirectional_36[0][0]           \n",
      "                                                                 bidirectional_37[0][0]           \n",
      "                                                                 bidirectional_38[0][0]           \n",
      "                                                                 bidirectional_39[0][0]           \n",
      "                                                                 bidirectional_40[0][0]           \n",
      "                                                                 bidirectional_41[0][0]           \n",
      "                                                                 bidirectional_42[0][0]           \n",
      "                                                                 bidirectional_43[0][0]           \n",
      "                                                                 bidirectional_44[0][0]           \n",
      "                                                                 bidirectional_45[0][0]           \n",
      "                                                                 bidirectional_46[0][0]           \n",
      "                                                                 bidirectional_47[0][0]           \n",
      "                                                                 bidirectional_48[0][0]           \n",
      "                                                                 bidirectional_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 57, 64)       6528        reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 57, 1)        0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 57, 1)        9           dense_9[0][0]                    \n",
      "                                                                 dense_9[1][0]                    \n",
      "                                                                 dense_9[2][0]                    \n",
      "                                                                 dense_9[3][0]                    \n",
      "                                                                 dense_9[4][0]                    \n",
      "                                                                 dense_9[5][0]                    \n",
      "                                                                 dense_9[6][0]                    \n",
      "                                                                 dense_9[7][0]                    \n",
      "                                                                 dense_9[8][0]                    \n",
      "                                                                 dense_9[9][0]                    \n",
      "                                                                 dense_9[10][0]                   \n",
      "                                                                 dense_9[11][0]                   \n",
      "                                                                 dense_9[12][0]                   \n",
      "                                                                 dense_9[13][0]                   \n",
      "                                                                 dense_9[14][0]                   \n",
      "                                                                 dense_9[15][0]                   \n",
      "                                                                 dense_9[16][0]                   \n",
      "                                                                 dense_9[17][0]                   \n",
      "                                                                 dense_9[18][0]                   \n",
      "                                                                 dense_9[19][0]                   \n",
      "                                                                 dense_9[20][0]                   \n",
      "                                                                 dense_9[21][0]                   \n",
      "                                                                 dense_9[22][0]                   \n",
      "                                                                 dense_9[23][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 57, 64)       6528        reshape_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_60 (Reshape)            (None, 57, 1)        0           lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights1 (Activation) (None, 57, 1)        0           dense_12[0][0]                   \n",
      "                                                                 dense_12[1][0]                   \n",
      "                                                                 dense_12[2][0]                   \n",
      "                                                                 dense_12[3][0]                   \n",
      "                                                                 dense_12[4][0]                   \n",
      "                                                                 dense_12[5][0]                   \n",
      "                                                                 dense_12[6][0]                   \n",
      "                                                                 dense_12[7][0]                   \n",
      "                                                                 dense_12[8][0]                   \n",
      "                                                                 dense_12[9][0]                   \n",
      "                                                                 dense_12[10][0]                  \n",
      "                                                                 dense_12[11][0]                  \n",
      "                                                                 dense_12[12][0]                  \n",
      "                                                                 dense_12[13][0]                  \n",
      "                                                                 dense_12[14][0]                  \n",
      "                                                                 dense_12[15][0]                  \n",
      "                                                                 dense_12[16][0]                  \n",
      "                                                                 dense_12[17][0]                  \n",
      "                                                                 dense_12[18][0]                  \n",
      "                                                                 dense_12[19][0]                  \n",
      "                                                                 dense_12[20][0]                  \n",
      "                                                                 dense_12[21][0]                  \n",
      "                                                                 dense_12[22][0]                  \n",
      "                                                                 dense_12[23][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, 57, 64)       6528        reshape_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_62 (Reshape)            (None, 57, 1)        0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     multiple             0           attention_weights1[0][0]         \n",
      "                                                                 bidirectional_26[0][0]           \n",
      "                                                                 attention_weights1[1][0]         \n",
      "                                                                 bidirectional_27[0][0]           \n",
      "                                                                 attention_weights1[2][0]         \n",
      "                                                                 bidirectional_28[0][0]           \n",
      "                                                                 attention_weights1[3][0]         \n",
      "                                                                 bidirectional_29[0][0]           \n",
      "                                                                 attention_weights1[4][0]         \n",
      "                                                                 bidirectional_30[0][0]           \n",
      "                                                                 attention_weights1[5][0]         \n",
      "                                                                 bidirectional_31[0][0]           \n",
      "                                                                 attention_weights1[6][0]         \n",
      "                                                                 bidirectional_32[0][0]           \n",
      "                                                                 attention_weights1[7][0]         \n",
      "                                                                 bidirectional_33[0][0]           \n",
      "                                                                 attention_weights1[8][0]         \n",
      "                                                                 bidirectional_34[0][0]           \n",
      "                                                                 attention_weights1[9][0]         \n",
      "                                                                 bidirectional_35[0][0]           \n",
      "                                                                 attention_weights1[10][0]        \n",
      "                                                                 bidirectional_36[0][0]           \n",
      "                                                                 attention_weights1[11][0]        \n",
      "                                                                 bidirectional_37[0][0]           \n",
      "                                                                 attention_weights1[12][0]        \n",
      "                                                                 bidirectional_38[0][0]           \n",
      "                                                                 attention_weights1[13][0]        \n",
      "                                                                 bidirectional_39[0][0]           \n",
      "                                                                 attention_weights1[14][0]        \n",
      "                                                                 bidirectional_40[0][0]           \n",
      "                                                                 attention_weights1[15][0]        \n",
      "                                                                 bidirectional_41[0][0]           \n",
      "                                                                 attention_weights1[16][0]        \n",
      "                                                                 bidirectional_42[0][0]           \n",
      "                                                                 attention_weights1[17][0]        \n",
      "                                                                 bidirectional_43[0][0]           \n",
      "                                                                 attention_weights1[18][0]        \n",
      "                                                                 bidirectional_44[0][0]           \n",
      "                                                                 attention_weights1[19][0]        \n",
      "                                                                 bidirectional_45[0][0]           \n",
      "                                                                 attention_weights1[20][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 bidirectional_46[0][0]           \n",
      "                                                                 attention_weights1[21][0]        \n",
      "                                                                 bidirectional_47[0][0]           \n",
      "                                                                 attention_weights1[22][0]        \n",
      "                                                                 bidirectional_48[0][0]           \n",
      "                                                                 attention_weights1[23][0]        \n",
      "                                                                 bidirectional_49[0][0]           \n",
      "                                                                 attention_weights2[0][0]         \n",
      "                                                                 bidirectional_50[0][0]           \n",
      "                                                                 attention_weights3[0][0]         \n",
      "                                                                 concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional (None, 57, 64)       6528        reshape_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_64 (Reshape)            (None, 57, 1)        0           lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_53 (Reshape)            (None, 64)           0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 64)           0           dot_2[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_32 (Bidirectional (None, 57, 64)       6528        reshape_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_66 (Reshape)            (None, 57, 1)        0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 128)          0           reshape_53[0][0]                 \n",
      "                                                                 reshape_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 64)           0           dot_2[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_33 (Bidirectional (None, 57, 64)       6528        reshape_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_68 (Reshape)            (None, 57, 1)        0           lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 192)          0           concatenate_31[0][0]             \n",
      "                                                                 reshape_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_59 (Reshape)            (None, 64)           0           dot_2[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_34 (Bidirectional (None, 57, 64)       6528        reshape_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 57, 1)        0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 256)          0           concatenate_32[0][0]             \n",
      "                                                                 reshape_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_61 (Reshape)            (None, 64)           0           dot_2[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_35 (Bidirectional (None, 57, 64)       6528        reshape_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_72 (Reshape)            (None, 57, 1)        0           lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 320)          0           concatenate_33[0][0]             \n",
      "                                                                 reshape_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_63 (Reshape)            (None, 64)           0           dot_2[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 57, 64)       6528        reshape_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_74 (Reshape)            (None, 57, 1)        0           lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 384)          0           concatenate_34[0][0]             \n",
      "                                                                 reshape_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_65 (Reshape)            (None, 64)           0           dot_2[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 57, 64)       6528        reshape_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_76 (Reshape)            (None, 57, 1)        0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 448)          0           concatenate_35[0][0]             \n",
      "                                                                 reshape_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_67 (Reshape)            (None, 64)           0           dot_2[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 57, 64)       6528        reshape_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_78 (Reshape)            (None, 57, 1)        0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 512)          0           concatenate_36[0][0]             \n",
      "                                                                 reshape_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_69 (Reshape)            (None, 64)           0           dot_2[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_39 (Bidirectional (None, 57, 64)       6528        reshape_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_80 (Reshape)            (None, 57, 1)        0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 576)          0           concatenate_37[0][0]             \n",
      "                                                                 reshape_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_71 (Reshape)            (None, 64)           0           dot_2[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_40 (Bidirectional (None, 57, 64)       6528        reshape_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_82 (Reshape)            (None, 57, 1)        0           lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 640)          0           concatenate_38[0][0]             \n",
      "                                                                 reshape_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_73 (Reshape)            (None, 64)           0           dot_2[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_41 (Bidirectional (None, 57, 64)       6528        reshape_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_84 (Reshape)            (None, 57, 1)        0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 704)          0           concatenate_39[0][0]             \n",
      "                                                                 reshape_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_75 (Reshape)            (None, 64)           0           dot_2[11][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_42 (Bidirectional (None, 57, 64)       6528        reshape_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_86 (Reshape)            (None, 57, 1)        0           lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 768)          0           concatenate_40[0][0]             \n",
      "                                                                 reshape_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_77 (Reshape)            (None, 64)           0           dot_2[12][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_43 (Bidirectional (None, 57, 64)       6528        reshape_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_88 (Reshape)            (None, 57, 1)        0           lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 832)          0           concatenate_41[0][0]             \n",
      "                                                                 reshape_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_79 (Reshape)            (None, 64)           0           dot_2[13][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_44 (Bidirectional (None, 57, 64)       6528        reshape_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_90 (Reshape)            (None, 57, 1)        0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 896)          0           concatenate_42[0][0]             \n",
      "                                                                 reshape_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_81 (Reshape)            (None, 64)           0           dot_2[14][0]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "bidirectional_45 (Bidirectional (None, 57, 64)       6528        reshape_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_92 (Reshape)            (None, 57, 1)        0           lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 960)          0           concatenate_43[0][0]             \n",
      "                                                                 reshape_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_83 (Reshape)            (None, 64)           0           dot_2[15][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_46 (Bidirectional (None, 57, 64)       6528        reshape_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_94 (Reshape)            (None, 57, 1)        0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 1024)         0           concatenate_44[0][0]             \n",
      "                                                                 reshape_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_85 (Reshape)            (None, 64)           0           dot_2[16][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_47 (Bidirectional (None, 57, 64)       6528        reshape_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_96 (Reshape)            (None, 57, 1)        0           lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 57)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 1088)         0           concatenate_45[0][0]             \n",
      "                                                                 reshape_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_87 (Reshape)            (None, 64)           0           dot_2[17][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_48 (Bidirectional (None, 57, 64)       6528        reshape_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_98 (Reshape)            (None, 57, 1)        0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 1152)         0           concatenate_46[0][0]             \n",
      "                                                                 reshape_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_89 (Reshape)            (None, 64)           0           dot_2[18][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_49 (Bidirectional (None, 57, 64)       6528        reshape_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 1216)         0           concatenate_47[0][0]             \n",
      "                                                                 reshape_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_91 (Reshape)            (None, 64)           0           dot_2[19][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 1280)         0           concatenate_48[0][0]             \n",
      "                                                                 reshape_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_93 (Reshape)            (None, 64)           0           dot_2[20][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 1344)         0           concatenate_49[0][0]             \n",
      "                                                                 reshape_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_95 (Reshape)            (None, 64)           0           dot_2[21][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 1408)         0           concatenate_50[0][0]             \n",
      "                                                                 reshape_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_97 (Reshape)            (None, 64)           0           dot_2[22][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 1472)         0           concatenate_51[0][0]             \n",
      "                                                                 reshape_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_99 (Reshape)            (None, 64)           0           dot_2[23][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 1536)         0           concatenate_52[0][0]             \n",
      "                                                                 reshape_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_100 (Reshape)           (None, 24, 64)       0           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 24, 6)        60          input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 24, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_50 (Bidirectional (None, 24, 64)       18624       reshape_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 24, 11)       0           time_distributed_7[0][0]         \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 24, 8)        520         bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 24, 8)        96          concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 24, 1)        9           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 24, 1)        9           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights2 (Activation) (None, 24, 1)        0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights3 (Activation) (None, 24, 1)        0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_101 (Reshape)           (None, 64)           0           dot_2[24][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_102 (Reshape)           (None, 11)           0           dot_2[25][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 75)           0           reshape_101[0][0]                \n",
      "                                                                 reshape_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 24)           1824        concatenate_56[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 178,510\n",
      "Trainable params: 178,496\n",
      "Non-trainable params: 14\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.458 26.016\n"
     ]
    }
   ],
   "source": [
    "pre_test=model.predict([time_m_test,w_m_test,wea_m_test,ge_m_test,sd_m_test])\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.round(mean_absolute_error(pre_test,td_test[:145]),3),np.round(np.sqrt(mean_squared_error(pre_test,td_test[:145])),3))\n",
    "# mean_absolute_error(pre_test,td_test[:145]),np.sqrt(mean_squared_error(pre_test,td_test[:145]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.zeros(shape=(1,24,54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=np.zeros(shape=(1,24,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=9\n",
    "pre_testi=model.predict([time_m_test[i].reshape(1,24,3),w_m_test[i].reshape(1,24,3),wea_m_test[i].reshape(1,24,5),ge_m_test[i].reshape(1,24,16,16,3),sd_m_test[i].reshape(1,24,54)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_testj=model.predict([time_m_test[i].reshape(1,24,3),w_m_test[i].reshape(1,24,3),wea_m_test[i].reshape(1,24,5),g,sd_m_test[i].reshape(1,24,54)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_testr=model.predict([time_m_test[i].reshape(1,24,3),w_m_test[i].reshape(1,24,3),wea_m_test[i].reshape(1,24,5),ge_m_test[i].reshape(1,24,16,16,3),s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.974980946222942, 0.77671238199869796, -3.1569006004333495)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((pre_testr-td_test[:145][i]))/24,np.sum((pre_testj-td_test[:145][i]))/24,np.sum((pre_testi-td_test[:145][i]))/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.994792243321736, 8.0281483434041334, 8.2958747495015448)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(pre_testr-td_test[:145][i]))/24,np.sum(np.abs(pre_testj-td_test[:145][i]))/24,np.sum(np.abs(pre_testi-td_test[:145][i]))/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e2e62689d246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ADHN_me_24_model_18.098.h5'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# creates a HDF5 file 'my_model.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# returns a compiled model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1088\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0m_serialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[1;34m(model, f, include_optimizer)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mmodel_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_node_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output_layers'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0mappend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# If is its own copy, don't memoize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# If is its own copy, don't memoize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# If is its own copy, don't memoize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__setstate__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce_ex__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreductor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                         \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('ADHN_me_24_model_18.098.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('air_traff_model.h5',custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 24, 16, 16, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 24, 3)        167         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 24, 55)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 58)       0           time_distributed_1[0][0]         \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 58, 1)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 58, 1)        0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 58, 64)       6528        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 58, 64)       6528        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 58, 1)        0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 58, 8)        520         bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "                                                                 bidirectional_18[0][0]           \n",
      "                                                                 bidirectional_19[0][0]           \n",
      "                                                                 bidirectional_20[0][0]           \n",
      "                                                                 bidirectional_21[0][0]           \n",
      "                                                                 bidirectional_22[0][0]           \n",
      "                                                                 bidirectional_23[0][0]           \n",
      "                                                                 bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 58, 64)       6528        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 58, 1)        0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 58, 1)        9           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "                                                                 dense_1[20][0]                   \n",
      "                                                                 dense_1[21][0]                   \n",
      "                                                                 dense_1[22][0]                   \n",
      "                                                                 dense_1[23][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 58, 64)       6528        reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 58, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights1 (Activation) (None, 58, 1)        0           dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_3[2][0]                    \n",
      "                                                                 dense_3[3][0]                    \n",
      "                                                                 dense_3[4][0]                    \n",
      "                                                                 dense_3[5][0]                    \n",
      "                                                                 dense_3[6][0]                    \n",
      "                                                                 dense_3[7][0]                    \n",
      "                                                                 dense_3[8][0]                    \n",
      "                                                                 dense_3[9][0]                    \n",
      "                                                                 dense_3[10][0]                   \n",
      "                                                                 dense_3[11][0]                   \n",
      "                                                                 dense_3[12][0]                   \n",
      "                                                                 dense_3[13][0]                   \n",
      "                                                                 dense_3[14][0]                   \n",
      "                                                                 dense_3[15][0]                   \n",
      "                                                                 dense_3[16][0]                   \n",
      "                                                                 dense_3[17][0]                   \n",
      "                                                                 dense_3[18][0]                   \n",
      "                                                                 dense_3[19][0]                   \n",
      "                                                                 dense_3[20][0]                   \n",
      "                                                                 dense_3[21][0]                   \n",
      "                                                                 dense_3[22][0]                   \n",
      "                                                                 dense_3[23][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 58, 64)       6528        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 58, 1)        0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights1[0][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights1[1][0]         \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 attention_weights1[2][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights1[3][0]         \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 attention_weights1[4][0]         \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 attention_weights1[5][0]         \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 attention_weights1[6][0]         \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 attention_weights1[7][0]         \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 attention_weights1[8][0]         \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 attention_weights1[9][0]         \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 attention_weights1[10][0]        \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 attention_weights1[11][0]        \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 attention_weights1[12][0]        \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 attention_weights1[13][0]        \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 attention_weights1[14][0]        \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 attention_weights1[15][0]        \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 attention_weights1[16][0]        \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "                                                                 attention_weights1[17][0]        \n",
      "                                                                 bidirectional_18[0][0]           \n",
      "                                                                 attention_weights1[18][0]        \n",
      "                                                                 bidirectional_19[0][0]           \n",
      "                                                                 attention_weights1[19][0]        \n",
      "                                                                 bidirectional_20[0][0]           \n",
      "                                                                 attention_weights1[20][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 bidirectional_21[0][0]           \n",
      "                                                                 attention_weights1[21][0]        \n",
      "                                                                 bidirectional_22[0][0]           \n",
      "                                                                 attention_weights1[22][0]        \n",
      "                                                                 bidirectional_23[0][0]           \n",
      "                                                                 attention_weights1[23][0]        \n",
      "                                                                 bidirectional_24[0][0]           \n",
      "                                                                 attention_weights2[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 58, 64)       6528        reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 58, 1)        0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 64)           0           dot_1[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 58, 64)       6528        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 58, 1)        0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           reshape_2[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 64)           0           dot_1[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 58, 64)       6528        reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 58, 1)        0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 192)          0           concatenate_3[0][0]              \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 64)           0           dot_1[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 58, 64)       6528        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 58, 1)        0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256)          0           concatenate_4[0][0]              \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 64)           0           dot_1[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 58, 64)       6528        reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 58, 1)        0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 320)          0           concatenate_5[0][0]              \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 64)           0           dot_1[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 58, 64)       6528        reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 58, 1)        0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 384)          0           concatenate_6[0][0]              \n",
      "                                                                 reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 64)           0           dot_1[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 58, 64)       6528        reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 58, 1)        0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 448)          0           concatenate_7[0][0]              \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 64)           0           dot_1[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 58, 64)       6528        reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 58, 1)        0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 512)          0           concatenate_8[0][0]              \n",
      "                                                                 reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 64)           0           dot_1[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 58, 64)       6528        reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 58, 1)        0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 576)          0           concatenate_9[0][0]              \n",
      "                                                                 reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 64)           0           dot_1[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 58, 64)       6528        reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 58, 1)        0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 640)          0           concatenate_10[0][0]             \n",
      "                                                                 reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 64)           0           dot_1[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 58, 64)       6528        reshape_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 58, 1)        0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 704)          0           concatenate_11[0][0]             \n",
      "                                                                 reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 64)           0           dot_1[11][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 58, 64)       6528        reshape_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_35 (Reshape)            (None, 58, 1)        0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 768)          0           concatenate_12[0][0]             \n",
      "                                                                 reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 64)           0           dot_1[12][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 58, 64)       6528        reshape_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 58, 1)        0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 832)          0           concatenate_13[0][0]             \n",
      "                                                                 reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 64)           0           dot_1[13][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 58, 64)       6528        reshape_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_39 (Reshape)            (None, 58, 1)        0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 896)          0           concatenate_14[0][0]             \n",
      "                                                                 reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 64)           0           dot_1[14][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 58, 64)       6528        reshape_39[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "reshape_41 (Reshape)            (None, 58, 1)        0           lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 960)          0           concatenate_15[0][0]             \n",
      "                                                                 reshape_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 64)           0           dot_1[15][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 58, 64)       6528        reshape_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_43 (Reshape)            (None, 58, 1)        0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1024)         0           concatenate_16[0][0]             \n",
      "                                                                 reshape_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 64)           0           dot_1[16][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 58, 64)       6528        reshape_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_45 (Reshape)            (None, 58, 1)        0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 58)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 1088)         0           concatenate_17[0][0]             \n",
      "                                                                 reshape_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 64)           0           dot_1[17][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 58, 64)       6528        reshape_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_47 (Reshape)            (None, 58, 1)        0           lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 1152)         0           concatenate_18[0][0]             \n",
      "                                                                 reshape_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 64)           0           dot_1[18][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 58, 64)       6528        reshape_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 1216)         0           concatenate_19[0][0]             \n",
      "                                                                 reshape_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)            (None, 64)           0           dot_1[19][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 1280)         0           concatenate_20[0][0]             \n",
      "                                                                 reshape_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_42 (Reshape)            (None, 64)           0           dot_1[20][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 1344)         0           concatenate_21[0][0]             \n",
      "                                                                 reshape_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_44 (Reshape)            (None, 64)           0           dot_1[21][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 1408)         0           concatenate_22[0][0]             \n",
      "                                                                 reshape_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_46 (Reshape)            (None, 64)           0           dot_1[22][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 1472)         0           concatenate_23[0][0]             \n",
      "                                                                 reshape_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 64)           0           dot_1[23][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 24, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 1536)         0           concatenate_24[0][0]             \n",
      "                                                                 reshape_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 24, 9)        108         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 24, 6)        60          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 24, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 24, 64)       0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 24, 84)       0           time_distributed_2[0][0]         \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 reshape_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 64)       5440        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 64)       8256        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 24, 64)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 24, 64)       0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 64)       0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 64)       8256        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 24, 64)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 64)       0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 64)       0           add_1[0][0]                      \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 64)       8256        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 24, 64)       0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 64)       0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 64)       0           add_2[0][0]                      \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 64)       8256        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 64)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 24, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 64)       0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 64)       0           add_3[0][0]                      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 64)       8256        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 24, 64)       0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 24, 64)       0           lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 64)       0           add_4[0][0]                      \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 24, 64)       8256        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 64)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 24, 64)       0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 24, 64)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_6[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 24, 64)       0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 64)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24, 1)        65          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights2 (Activation) (None, 24, 1)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_50 (Reshape)            (None, 64)           0           dot_1[24][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 24)           1560        reshape_50[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 239,097\n",
      "Trainable params: 239,065\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1, 57, 1)\n"
     ]
    }
   ],
   "source": [
    "i=22\n",
    "#取某一层的输出为输出新建为model，采用函数模型\n",
    "dense1_layer_model = Model(inputs=model.input,outputs=[model.get_layer('attention_weights1').get_output_at(t) for t in range(24)])\n",
    "dense1_output = dense1_layer_model.predict([time_m_test[i].reshape(1,24,3),w_m_test[i].reshape(1,24,3),wea_m_test[i].reshape(1,24,5),ge_m_test[i].reshape(1,24,16,16,3),sd_m_test[i].reshape(1,24,54)])\n",
    "# dense1_output = dense1_layer_model.predict([time_m,w_m,wea_m,ge_m,sd_m])\n",
    "\n",
    "\n",
    "\n",
    "print( np.shape(dense1_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tain_att=np.reshape(dense1_output,(5801, 24, 58))\n",
    "tain_att1=np.reshape(dense1_output,(24, 57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 57)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tain_att1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.91518730e-02,   1.71804894e-02,   3.20420833e-03, ...,\n",
       "          1.48472539e-03,   1.48472539e-03,   1.48472539e-03],\n",
       "       [  9.76950279e-04,   4.97437664e-04,   2.78195337e-04, ...,\n",
       "          1.60802796e-03,   1.73906353e-03,   8.42469686e-04],\n",
       "       [  4.00149554e-01,   1.28710613e-01,   2.97778025e-02, ...,\n",
       "          2.89658038e-03,   2.89658038e-03,   2.89658038e-03],\n",
       "       ..., \n",
       "       [  3.84594011e-03,   1.81557762e-03,   1.22509513e-03, ...,\n",
       "          8.86732014e-04,   8.86732014e-04,   8.86732014e-04],\n",
       "       [  4.69178340e-04,   3.21583415e-04,   6.04357221e-04, ...,\n",
       "          8.35640676e-05,   8.35640676e-05,   8.35640676e-05],\n",
       "       [  1.24860392e-03,   1.34489744e-03,   3.84101388e-03, ...,\n",
       "          1.24860392e-03,   1.24860392e-03,   1.78122637e-03]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tain_att1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(tain_att.sum(axis=0))\n",
    "train_att=tain_att.sum(axis=0)/tain_att.sum(axis=0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tain_att1).to_csv('../train_att20150420.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = K.function(model.inputs, [model.get_layer('dense_21').get_output_at(0) for t in range(24)])\n",
    "# f = K.function(model.inputs, [model.get_layer('attention_weights3').output])\n",
    "\n",
    "f = K.function(model.inputs, [model.get_layer('concatenate_55').output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=22\n",
    "\n",
    "# r = f([time_m_test[1].reshape(1,24,3),w_m_test[1].reshape(1,24,3),wea_m_test[1].reshape(1,24,5),ge_m_test[1].reshape(1,24,16,16,3),sd_m_test[1].reshape(1,24,55)])\n",
    "\n",
    "r = f([time_m_test[t].reshape(1,24,3),w_m_test[t].reshape(1,24,3),wea_m_test[t].reshape(1,24,5),ge_m_test[t].reshape(1,24,16,16,3),sd_m_test[t].reshape(1,24,54)])\n",
    "\n",
    "# r = f([time_m,w_m,wea_m,ge_m,sd_m])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 24, 11)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ -1.40529501e+00,  -1.76683807e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.00000000e+01,   8.80000000e+01,   1.00900000e+03,\n",
       "            1.20000000e+01,   2.87999992e+01],\n",
       "         [ -1.40529501e+00,  -1.76683807e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.00000000e+01,   8.80000000e+01,   1.00900000e+03,\n",
       "            1.20000000e+01,   2.52000008e+01],\n",
       "         [  5.04610300e+00,   1.23163319e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,  -1.68859208e+00,   2.45984697e+00,\n",
       "            1.10000000e+01,   9.40000000e+01,   1.01000000e+03,\n",
       "            1.20000000e+01,   2.52000008e+01],\n",
       "         [  5.04610300e+00,   1.23163319e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,  -1.68859208e+00,   2.45984697e+00,\n",
       "            1.10000000e+01,   9.40000000e+01,   1.01100000e+03,\n",
       "            1.20000000e+01,   1.80000000e+01],\n",
       "         [ -1.40529501e+00,  -1.76683807e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.10000000e+01,   9.40000000e+01,   1.01200000e+03,\n",
       "            1.20000000e+01,   2.16000004e+01],\n",
       "         [  5.04610300e+00,   1.23163319e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.10000000e+01,   9.40000000e+01,   1.01200000e+03,\n",
       "            1.20000000e+01,   2.52000008e+01],\n",
       "         [  5.04610300e+00,   1.23163319e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.10000000e+01,   8.20000000e+01,   1.01300000e+03,\n",
       "            1.40000000e+01,   2.16000004e+01],\n",
       "         [  5.04610300e+00,   1.23163319e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.00000000e+01,   7.70000000e+01,   1.01300000e+03,\n",
       "            1.40000000e+01,   2.16000004e+01],\n",
       "         [ -7.14531064e-01,   4.98808002e+00,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            1.00000000e+01,   7.20000000e+01,   1.01300000e+03,\n",
       "            1.50000000e+01,   1.80000000e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            7.00000000e+00,   5.50000000e+01,   1.01300000e+03,\n",
       "            1.60000000e+01,   1.80000000e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            4.00000000e+00,   5.10000000e+01,   1.01400000e+03,\n",
       "            1.40000000e+01,   2.16000004e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            3.00000000e+00,   4.80000000e+01,   1.01400000e+03,\n",
       "            1.40000000e+01,   1.80000000e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            4.00000000e+00,   5.40000000e+01,   1.01600000e+03,\n",
       "            1.30000000e+01,   1.80000000e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            4.00000000e+00,   5.80000000e+01,   1.01600000e+03,\n",
       "            1.20000000e+01,   1.43999996e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   5.10000000e+01,   1.01700000e+03,\n",
       "            1.20000000e+01,   1.80000000e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   5.40000000e+01,   1.01600000e+03,\n",
       "            1.10000000e+01,   1.08000002e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   5.40000000e+01,   1.01700000e+03,\n",
       "            1.10000000e+01,   1.08000002e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   5.80000000e+01,   1.01700000e+03,\n",
       "            1.00000000e+01,   1.08000002e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   5.80000000e+01,   1.01700000e+03,\n",
       "            1.00000000e+01,   1.08000002e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   6.20000000e+01,   1.01700000e+03,\n",
       "            9.00000000e+00,   1.08000002e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   6.60000000e+01,   1.01700000e+03,\n",
       "            8.00000000e+00,   1.43999996e+01],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            2.00000000e+00,   6.60000000e+01,   1.01700000e+03,\n",
       "            8.00000000e+00,   7.19999981e+00],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            4.00000000e+00,   7.60000000e+01,   1.01800000e+03,\n",
       "            8.00000000e+00,   7.19999981e+00],\n",
       "         [ -8.82666707e-02,  -1.39795959e-01,   1.89262629e-02,\n",
       "            1.81271076e-01,   5.69797754e-02,  -8.74749541e-01,\n",
       "            5.00000000e+00,   6.20000000e+01,   1.01900000e+03,\n",
       "            1.20000000e+01,   7.19999981e+00]]], dtype=float32)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=np.reshape(r,(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=r1.sum(axis=0)/r1.sum(axis=0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  4.6130619,  0.       ], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1be99e01278>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = [i for i in range(24)]    \n",
    "plt.plot(x,r2,color='red',label='APP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "fig = pl.figure(1)\n",
    "X = [i for i in range(24)]  \n",
    "pl.plot(X,r1, color ='red', linewidth = 1.0, linestyle ='-',label='Straight-forward Structure')\n",
    "# pl.plot(X,value2, color ='green',linewidth=1.0, linestyle='-', label='Single-branch Structure')\n",
    "# pl.plot(X,value3, color ='red', linewidth=1.0, linestyle='--',label='Double-branch Structure')\n",
    "pl.legend(loc='upper right')\n",
    " \n",
    "pl.title('SingleBranch(Blue) DoubleBranch(Green) TribleBranch(Red)')\n",
    " \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_att20150420_new=pd.read_csv('train_att20150420_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04157566,  0.04159852,  0.04168886,  0.04158795,  0.04162821,\n",
       "         0.04172351,  0.0417479 ],\n",
       "       [ 0.04164159,  0.04160962,  0.04162679,  0.04159317,  0.04174608,\n",
       "         0.04169896,  0.04170854],\n",
       "       [ 0.04166624,  0.04169966,  0.04167431,  0.04164252,  0.04184298,\n",
       "         0.04164863,  0.04158378],\n",
       "       [ 0.04175149,  0.04166782,  0.04168939,  0.04171015,  0.04188273,\n",
       "         0.04152452,  0.04157884],\n",
       "       [ 0.04177624,  0.04166177,  0.04169468,  0.04169304,  0.0418031 ,\n",
       "         0.04131206,  0.04171513],\n",
       "       [ 0.04177575,  0.04169378,  0.04175618,  0.04168269,  0.04175227,\n",
       "         0.04134091,  0.04168146],\n",
       "       [ 0.04176162,  0.04167136,  0.04175589,  0.04168832,  0.04182745,\n",
       "         0.0415293 ,  0.04156029],\n",
       "       [ 0.04176863,  0.04176956,  0.04176216,  0.04175674,  0.04173629,\n",
       "         0.04165192,  0.04144148],\n",
       "       [ 0.04178397,  0.04177614,  0.0417779 ,  0.04184628,  0.0417114 ,\n",
       "         0.04157037,  0.04143655],\n",
       "       [ 0.04184094,  0.0416775 ,  0.04179175,  0.04174567,  0.04164189,\n",
       "         0.04156312,  0.04155421],\n",
       "       [ 0.04176831,  0.04170182,  0.04172592,  0.04168692,  0.0416779 ,\n",
       "         0.04164096,  0.0415771 ],\n",
       "       [ 0.04173172,  0.04155674,  0.04164753,  0.0416733 ,  0.04165367,\n",
       "         0.0417766 ,  0.04167001],\n",
       "       [ 0.04166281,  0.04158912,  0.04158817,  0.04175642,  0.04159654,\n",
       "         0.04167363,  0.04173877],\n",
       "       [ 0.04159548,  0.0415749 ,  0.04157587,  0.04168201,  0.04163087,\n",
       "         0.04180864,  0.04173412],\n",
       "       [ 0.04163635,  0.04163696,  0.04156181,  0.04168767,  0.04174591,\n",
       "         0.04187972,  0.04159718],\n",
       "       [ 0.04167868,  0.0416177 ,  0.04147244,  0.04174522,  0.04176817,\n",
       "         0.04191294,  0.04157885],\n",
       "       [ 0.04155879,  0.04159839,  0.04150755,  0.04173966,  0.04174935,\n",
       "         0.04185317,  0.04165777],\n",
       "       [ 0.04160946,  0.04154691,  0.04163346,  0.04160705,  0.04158881,\n",
       "         0.04177307,  0.04178291],\n",
       "       [ 0.0416022 ,  0.04170159,  0.04163742,  0.04161782,  0.04151259,\n",
       "         0.04168952,  0.04177334],\n",
       "       [ 0.04148994,  0.04164886,  0.04155141,  0.04162594,  0.04149036,\n",
       "         0.04168283,  0.04189378],\n",
       "       [ 0.04156055,  0.04166899,  0.04156339,  0.04156082,  0.04144959,\n",
       "         0.04159327,  0.04194755],\n",
       "       [ 0.04162064,  0.04181807,  0.04170919,  0.04152054,  0.04144835,\n",
       "         0.04158281,  0.04180401],\n",
       "       [ 0.04156369,  0.04181555,  0.0418522 ,  0.04158844,  0.04157732,\n",
       "         0.04174842,  0.04156727],\n",
       "       [ 0.04157913,  0.04169865,  0.04175574,  0.04156166,  0.04153821,\n",
       "         0.04182111,  0.04166917]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '0'),\n",
       " Text(0, 1.5, '1'),\n",
       " Text(0, 2.5, '2'),\n",
       " Text(0, 3.5, '3'),\n",
       " Text(0, 4.5, '4'),\n",
       " Text(0, 5.5, '5'),\n",
       " Text(0, 6.5, '6'),\n",
       " Text(0, 7.5, '7'),\n",
       " Text(0, 8.5, '8'),\n",
       " Text(0, 9.5, '9'),\n",
       " Text(0, 10.5, '10'),\n",
       " Text(0, 11.5, '11'),\n",
       " Text(0, 12.5, '12'),\n",
       " Text(0, 13.5, '13'),\n",
       " Text(0, 14.5, '14'),\n",
       " Text(0, 15.5, '15'),\n",
       " Text(0, 16.5, '16'),\n",
       " Text(0, 17.5, '17'),\n",
       " Text(0, 18.5, '18'),\n",
       " Text(0, 19.5, '19'),\n",
       " Text(0, 20.5, '20'),\n",
       " Text(0, 21.5, '21'),\n",
       " Text(0, 22.5, '22'),\n",
       " Text(0, 23.5, '23')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_attention=pd.read_csv('train_att.csv')\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "attention_map = np.zeros((24, 7))\n",
    "\n",
    "for t in range(24):\n",
    "        for t_prime in range(7):\n",
    "            attention_map[t][t_prime] = train_att20150420_new.values[t][t_prime]\n",
    "\n",
    "            \n",
    "source_list = train_att2.columns\n",
    "target_list = [i for i in range(24)]         \n",
    "f, ax = plt.subplots(figsize=(20,15))\n",
    "sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n",
    "\n",
    "# Y = model.predict([time_m_test,w_m_test,wea_m_test,ge_m_test,sd_m_test])\n",
    "\n",
    "#     source_list = sentence.split()\n",
    "#     target_list = Y.split()\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(20,15))\n",
    "#     sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "#     ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "#     ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_att20150420_newloc=pd.read_csv('train_att20150420_newloc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '0'),\n",
       " Text(0, 1.5, '1'),\n",
       " Text(0, 2.5, '2'),\n",
       " Text(0, 3.5, '3'),\n",
       " Text(0, 4.5, '4'),\n",
       " Text(0, 5.5, '5'),\n",
       " Text(0, 6.5, '6'),\n",
       " Text(0, 7.5, '7'),\n",
       " Text(0, 8.5, '8'),\n",
       " Text(0, 9.5, '9'),\n",
       " Text(0, 10.5, '10'),\n",
       " Text(0, 11.5, '11'),\n",
       " Text(0, 12.5, '12'),\n",
       " Text(0, 13.5, '13'),\n",
       " Text(0, 14.5, '14'),\n",
       " Text(0, 15.5, '15'),\n",
       " Text(0, 16.5, '16'),\n",
       " Text(0, 17.5, '17'),\n",
       " Text(0, 18.5, '18'),\n",
       " Text(0, 19.5, '19'),\n",
       " Text(0, 20.5, '20'),\n",
       " Text(0, 21.5, '21'),\n",
       " Text(0, 22.5, '22'),\n",
       " Text(0, 23.5, '23')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_attention=pd.read_csv('train_att.csv')\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "attention_map = np.zeros((24, 10))\n",
    "\n",
    "for t in range(24):\n",
    "        for t_prime in range(10):\n",
    "            attention_map[t][t_prime] = train_att20150420_newloc.values[t][t_prime]\n",
    "\n",
    "            \n",
    "source_list = train_att_loc.columns\n",
    "target_list = [i for i in range(24)]         \n",
    "f, ax = plt.subplots(figsize=(20,15))\n",
    "sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n",
    "\n",
    "# Y = model.predict([time_m_test,w_m_test,wea_m_test,ge_m_test,sd_m_test])\n",
    "\n",
    "#     source_list = sentence.split()\n",
    "#     target_list = Y.split()\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(20,15))\n",
    "#     sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "#     ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "#     ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 56.        ,  58.        ,  53.        , ...,   0.585     ,\n",
       "           0.9       ,  61.88888889],\n",
       "        [ 56.        ,  61.        ,  63.        , ...,   0.601     ,\n",
       "           0.985     ,  66.55555556],\n",
       "        [ 76.        ,  76.        ,  84.        , ...,   0.646     ,\n",
       "           1.067     ,  79.22222222],\n",
       "        ..., \n",
       "        [ 18.        ,  19.        ,  24.        , ...,   0.332     ,\n",
       "           0.677     ,  20.88888889],\n",
       "        [ 25.        ,  25.        ,  29.        , ...,   0.364     ,\n",
       "           0.699     ,  24.66666667],\n",
       "        [ 25.        ,  25.        ,  26.        , ...,   0.582     ,\n",
       "           0.716     ,  26.11111111]],\n",
       "\n",
       "       [[ 56.        ,  61.        ,  63.        , ...,   0.601     ,\n",
       "           0.985     ,  66.55555556],\n",
       "        [ 76.        ,  76.        ,  84.        , ...,   0.646     ,\n",
       "           1.067     ,  79.22222222],\n",
       "        [ 90.        ,  84.        ,  89.        , ...,   0.698     ,\n",
       "           1.092     ,  88.22222222],\n",
       "        ..., \n",
       "        [ 25.        ,  25.        ,  29.        , ...,   0.364     ,\n",
       "           0.699     ,  24.66666667],\n",
       "        [ 25.        ,  25.        ,  26.        , ...,   0.582     ,\n",
       "           0.716     ,  26.11111111],\n",
       "        [ 29.        ,  23.        ,  22.        , ...,   0.679     ,\n",
       "           0.775     ,  24.22222222]],\n",
       "\n",
       "       [[ 76.        ,  76.        ,  84.        , ...,   0.646     ,\n",
       "           1.067     ,  79.22222222],\n",
       "        [ 90.        ,  84.        ,  89.        , ...,   0.698     ,\n",
       "           1.092     ,  88.22222222],\n",
       "        [ 84.        ,  92.        ,  72.        , ...,   0.632     ,\n",
       "           0.976     ,  86.33333333],\n",
       "        ..., \n",
       "        [ 25.        ,  25.        ,  26.        , ...,   0.582     ,\n",
       "           0.716     ,  26.11111111],\n",
       "        [ 29.        ,  23.        ,  22.        , ...,   0.679     ,\n",
       "           0.775     ,  24.22222222],\n",
       "        [ 37.        ,  43.        ,  32.        , ...,   0.813     ,\n",
       "           0.901     ,  35.44444444]],\n",
       "\n",
       "       ..., \n",
       "       [[ 90.        ,  83.        ,  83.        , ...,   0.872     ,\n",
       "           1.097     ,  94.44444444],\n",
       "        [ 60.        ,  63.        ,  63.        , ...,   0.473     ,\n",
       "           0.85      ,  72.        ],\n",
       "        [ 67.        ,  57.        ,  57.        , ...,   0.376     ,\n",
       "           0.878     ,  65.44444444],\n",
       "        ..., \n",
       "        [ 39.        ,  40.        ,  40.        , ...,   0.304     ,\n",
       "           0.684     ,  38.77777778],\n",
       "        [ 33.        ,  34.        ,  34.        , ...,   0.355     ,\n",
       "           0.753     ,  34.        ],\n",
       "        [ 43.        ,  38.        ,  38.        , ...,   0.361     ,\n",
       "           0.804     ,  41.66666667]],\n",
       "\n",
       "       [[ 60.        ,  63.        ,  63.        , ...,   0.473     ,\n",
       "           0.85      ,  72.        ],\n",
       "        [ 67.        ,  57.        ,  57.        , ...,   0.376     ,\n",
       "           0.878     ,  65.44444444],\n",
       "        [ 63.        ,  62.        ,  62.        , ...,   0.393     ,\n",
       "           0.872     ,  59.11111111],\n",
       "        ..., \n",
       "        [ 33.        ,  34.        ,  34.        , ...,   0.355     ,\n",
       "           0.753     ,  34.        ],\n",
       "        [ 43.        ,  38.        ,  38.        , ...,   0.361     ,\n",
       "           0.804     ,  41.66666667],\n",
       "        [ 43.        ,  46.        ,  46.        , ...,   0.365     ,\n",
       "           0.836     ,  45.        ]],\n",
       "\n",
       "       [[ 67.        ,  57.        ,  57.        , ...,   0.376     ,\n",
       "           0.878     ,  65.44444444],\n",
       "        [ 63.        ,  62.        ,  62.        , ...,   0.393     ,\n",
       "           0.872     ,  59.11111111],\n",
       "        [ 56.        ,  42.        ,  42.        , ...,   0.394     ,\n",
       "           0.939     ,  46.77777778],\n",
       "        ..., \n",
       "        [ 43.        ,  38.        ,  38.        , ...,   0.361     ,\n",
       "           0.804     ,  41.66666667],\n",
       "        [ 43.        ,  46.        ,  46.        , ...,   0.365     ,\n",
       "           0.836     ,  45.        ],\n",
       "        [ 49.        ,  46.        ,  46.        , ...,   0.389     ,\n",
       "           0.853     ,  49.        ]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM25_1</th>\n",
       "      <th>PM25_2</th>\n",
       "      <th>PM25_3</th>\n",
       "      <th>PM25_4</th>\n",
       "      <th>PM25_5</th>\n",
       "      <th>PM25_6</th>\n",
       "      <th>...</th>\n",
       "      <th>CO_1</th>\n",
       "      <th>CO_2</th>\n",
       "      <th>CO_3</th>\n",
       "      <th>CO_4</th>\n",
       "      <th>CO_5</th>\n",
       "      <th>CO_6</th>\n",
       "      <th>CO_7</th>\n",
       "      <th>CO_8</th>\n",
       "      <th>CO_9</th>\n",
       "      <th>PM25_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>6007</td>\n",
       "      <td>6007</td>\n",
       "      <td>20150420</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.677</td>\n",
       "      <td>20.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>6008</td>\n",
       "      <td>6008</td>\n",
       "      <td>20150420</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.699</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>6009</td>\n",
       "      <td>6009</td>\n",
       "      <td>20150420</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>1.477</td>\n",
       "      <td>1.153</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.716</td>\n",
       "      <td>26.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>6010</td>\n",
       "      <td>6010</td>\n",
       "      <td>20150420</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.775</td>\n",
       "      <td>24.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>6011</td>\n",
       "      <td>6011</td>\n",
       "      <td>20150420</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.946</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.901</td>\n",
       "      <td>35.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>6012</td>\n",
       "      <td>6012</td>\n",
       "      <td>20150420</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.862</td>\n",
       "      <td>43.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>6013</td>\n",
       "      <td>6013</td>\n",
       "      <td>20150420</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.756</td>\n",
       "      <td>41.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>20150420</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.722</td>\n",
       "      <td>36.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>6015</td>\n",
       "      <td>6015</td>\n",
       "      <td>20150420</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751</td>\n",
       "      <td>1.136</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.765</td>\n",
       "      <td>34.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>6016</td>\n",
       "      <td>6016</td>\n",
       "      <td>20150420</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.154</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.815</td>\n",
       "      <td>38.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>6017</td>\n",
       "      <td>6017</td>\n",
       "      <td>20150420</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.088</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.845</td>\n",
       "      <td>42.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>6018</td>\n",
       "      <td>6018</td>\n",
       "      <td>20150420</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.076</td>\n",
       "      <td>45.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>6019</td>\n",
       "      <td>6019</td>\n",
       "      <td>20150420</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.761</td>\n",
       "      <td>1.063</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.572</td>\n",
       "      <td>1.148</td>\n",
       "      <td>51.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>6020</td>\n",
       "      <td>6020</td>\n",
       "      <td>20150420</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.067</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.036</td>\n",
       "      <td>60.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>6021</td>\n",
       "      <td>6021</td>\n",
       "      <td>20150420</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.836</td>\n",
       "      <td>1.113</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1.049</td>\n",
       "      <td>63.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>6022</td>\n",
       "      <td>6022</td>\n",
       "      <td>20150420</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007</td>\n",
       "      <td>1.178</td>\n",
       "      <td>1.183</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.736</td>\n",
       "      <td>69.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>6023</td>\n",
       "      <td>6023</td>\n",
       "      <td>20150420</td>\n",
       "      <td>17</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>76</td>\n",
       "      <td>52</td>\n",
       "      <td>83</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.054</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.681</td>\n",
       "      <td>64.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>6024</td>\n",
       "      <td>6024</td>\n",
       "      <td>20150420</td>\n",
       "      <td>19</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084</td>\n",
       "      <td>2.214</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.651</td>\n",
       "      <td>50.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>6025</td>\n",
       "      <td>6025</td>\n",
       "      <td>20150420</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>2.060</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.622</td>\n",
       "      <td>45.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>6026</td>\n",
       "      <td>6026</td>\n",
       "      <td>20150420</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.604</td>\n",
       "      <td>44.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>6027</td>\n",
       "      <td>6027</td>\n",
       "      <td>20150420</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.560</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>6028</td>\n",
       "      <td>6028</td>\n",
       "      <td>20150420</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142</td>\n",
       "      <td>1.548</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.547</td>\n",
       "      <td>37.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>6029</td>\n",
       "      <td>6029</td>\n",
       "      <td>20150421</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.576</td>\n",
       "      <td>37.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>6030</td>\n",
       "      <td>6030</td>\n",
       "      <td>20150421</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065</td>\n",
       "      <td>1.128</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.616</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>6031</td>\n",
       "      <td>6031</td>\n",
       "      <td>20150421</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.633</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>6032</td>\n",
       "      <td>6032</td>\n",
       "      <td>20150421</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>6033</td>\n",
       "      <td>6033</td>\n",
       "      <td>20150421</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.057</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.640</td>\n",
       "      <td>38.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>6034</td>\n",
       "      <td>6034</td>\n",
       "      <td>20150421</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.641</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>6035</td>\n",
       "      <td>6035</td>\n",
       "      <td>20150421</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.948</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.728</td>\n",
       "      <td>47.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>6036</td>\n",
       "      <td>6036</td>\n",
       "      <td>20150421</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.136</td>\n",
       "      <td>1.339</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.673</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.979</td>\n",
       "      <td>54.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>20150425</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>118</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>1.255</td>\n",
       "      <td>1.118</td>\n",
       "      <td>1.118</td>\n",
       "      <td>1.517</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.298</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>1.229</td>\n",
       "      <td>97.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>6123</td>\n",
       "      <td>6123</td>\n",
       "      <td>20150425</td>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>104</td>\n",
       "      <td>123</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513</td>\n",
       "      <td>1.318</td>\n",
       "      <td>1.318</td>\n",
       "      <td>2.159</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.414</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.266</td>\n",
       "      <td>99.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>6124</td>\n",
       "      <td>6124</td>\n",
       "      <td>20150425</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>111</td>\n",
       "      <td>127</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482</td>\n",
       "      <td>1.635</td>\n",
       "      <td>1.635</td>\n",
       "      <td>1.783</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.552</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.471</td>\n",
       "      <td>104.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>6125</td>\n",
       "      <td>6125</td>\n",
       "      <td>20150425</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>137</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.822</td>\n",
       "      <td>1.601</td>\n",
       "      <td>1.601</td>\n",
       "      <td>1.559</td>\n",
       "      <td>1.091</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.485</td>\n",
       "      <td>113.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>6126</td>\n",
       "      <td>6126</td>\n",
       "      <td>20150425</td>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>132</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.660</td>\n",
       "      <td>1.298</td>\n",
       "      <td>1.298</td>\n",
       "      <td>1.366</td>\n",
       "      <td>117.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>6127</td>\n",
       "      <td>6127</td>\n",
       "      <td>20150425</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "      <td>99</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1.633</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.691</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1.569</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.463</td>\n",
       "      <td>101.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>6128</td>\n",
       "      <td>6128</td>\n",
       "      <td>20150425</td>\n",
       "      <td>11</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>107</td>\n",
       "      <td>151</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1.097</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>6129</td>\n",
       "      <td>6129</td>\n",
       "      <td>20150425</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>81</td>\n",
       "      <td>121</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.850</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5945</th>\n",
       "      <td>6130</td>\n",
       "      <td>6130</td>\n",
       "      <td>20150425</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.878</td>\n",
       "      <td>65.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>6131</td>\n",
       "      <td>6131</td>\n",
       "      <td>20150425</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.872</td>\n",
       "      <td>59.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>6132</td>\n",
       "      <td>6132</td>\n",
       "      <td>20150425</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.939</td>\n",
       "      <td>46.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>6133</td>\n",
       "      <td>6133</td>\n",
       "      <td>20150425</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.069</td>\n",
       "      <td>43.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>6134</td>\n",
       "      <td>6134</td>\n",
       "      <td>20150425</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>62</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.135</td>\n",
       "      <td>46.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>6135</td>\n",
       "      <td>6135</td>\n",
       "      <td>20150425</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>71</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.562</td>\n",
       "      <td>1.147</td>\n",
       "      <td>53.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>6136</td>\n",
       "      <td>6136</td>\n",
       "      <td>20150425</td>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.734</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1.080</td>\n",
       "      <td>67.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>6137</td>\n",
       "      <td>6137</td>\n",
       "      <td>20150425</td>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.959</td>\n",
       "      <td>82.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>6138</td>\n",
       "      <td>6138</td>\n",
       "      <td>20150425</td>\n",
       "      <td>23</td>\n",
       "      <td>92</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>103</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>1.274</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.956</td>\n",
       "      <td>83.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>6139</td>\n",
       "      <td>6139</td>\n",
       "      <td>20150426</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.867</td>\n",
       "      <td>79.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>6140</td>\n",
       "      <td>6140</td>\n",
       "      <td>20150426</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.832</td>\n",
       "      <td>72.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>6141</td>\n",
       "      <td>6141</td>\n",
       "      <td>20150426</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.810</td>\n",
       "      <td>60.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>6142</td>\n",
       "      <td>6142</td>\n",
       "      <td>20150426</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.792</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>6143</td>\n",
       "      <td>6143</td>\n",
       "      <td>20150426</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.517</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.837</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>6144</td>\n",
       "      <td>6144</td>\n",
       "      <td>20150426</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.833</td>\n",
       "      <td>59.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>6145</td>\n",
       "      <td>6145</td>\n",
       "      <td>20150426</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.787</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>20150426</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.759</td>\n",
       "      <td>55.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>20150426</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.723</td>\n",
       "      <td>52.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>6148</td>\n",
       "      <td>6148</td>\n",
       "      <td>20150426</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.711</td>\n",
       "      <td>44.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>6149</td>\n",
       "      <td>6149</td>\n",
       "      <td>20150426</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.684</td>\n",
       "      <td>38.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>6150</td>\n",
       "      <td>6150</td>\n",
       "      <td>20150426</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.753</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>6151</td>\n",
       "      <td>6151</td>\n",
       "      <td>20150426</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.804</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1      date  hour  PM25_1  PM25_2  PM25_3  \\\n",
       "5822        6007          6007  20150420     0      18      19      24   \n",
       "5823        6008          6008  20150420     1      25      25      29   \n",
       "5824        6009          6009  20150420     2      25      25      26   \n",
       "5825        6010          6010  20150420     3      29      23      22   \n",
       "5826        6011          6011  20150420     4      37      43      32   \n",
       "5827        6012          6012  20150420     5      40      39      42   \n",
       "5828        6013          6013  20150420     6      32      37      40   \n",
       "5829        6014          6014  20150420     7      29      34      37   \n",
       "5830        6015          6015  20150420     8      33      34      32   \n",
       "5831        6016          6016  20150420     9      34      38      40   \n",
       "5832        6017          6017  20150420    10      36      44      42   \n",
       "5833        6018          6018  20150420    11      48      45      50   \n",
       "5834        6019          6019  20150420    12      54      53      56   \n",
       "5835        6020          6020  20150420    13      59      60      65   \n",
       "5836        6021          6021  20150420    14      67      66      72   \n",
       "5837        6022          6022  20150420    16      70      61      76   \n",
       "5838        6023          6023  20150420    17      63      57      76   \n",
       "5839        6024          6024  20150420    19      51      53      49   \n",
       "5840        6025          6025  20150420    20      45      49      44   \n",
       "5841        6026          6026  20150420    21      47      43      47   \n",
       "5842        6027          6027  20150420    22      43      39      39   \n",
       "5843        6028          6028  20150420    23      44      38      39   \n",
       "5844        6029          6029  20150421     0      49      38      37   \n",
       "5845        6030          6030  20150421     1      39      36      35   \n",
       "5846        6031          6031  20150421     2      36      33      41   \n",
       "5847        6032          6032  20150421     3      36      39      42   \n",
       "5848        6033          6033  20150421     4      33      40      43   \n",
       "5849        6034          6034  20150421     5      38      47      45   \n",
       "5850        6035          6035  20150421     6      43      51      49   \n",
       "5851        6036          6036  20150421     7      48      58      60   \n",
       "...          ...           ...       ...   ...     ...     ...     ...   \n",
       "5937        6122          6122  20150425     5     105      93      93   \n",
       "5938        6123          6123  20150425     6     109      94      94   \n",
       "5939        6124          6124  20150425     7     112     103     103   \n",
       "5940        6125          6125  20150425     8     116     114     114   \n",
       "5941        6126          6126  20150425     9     124     112     112   \n",
       "5942        6127          6127  20150425    10     114      93      93   \n",
       "5943        6128          6128  20150425    11      90      83      83   \n",
       "5944        6129          6129  20150425    13      60      63      63   \n",
       "5945        6130          6130  20150425    14      67      57      57   \n",
       "5946        6131          6131  20150425    16      63      62      62   \n",
       "5947        6132          6132  20150425    17      56      42      42   \n",
       "5948        6133          6133  20150425    18      40      32      32   \n",
       "5949        6134          6134  20150425    19      39      34      34   \n",
       "5950        6135          6135  20150425    20      50      42      42   \n",
       "5951        6136          6136  20150425    21      72      60      60   \n",
       "5952        6137          6137  20150425    22      90      84      84   \n",
       "5953        6138          6138  20150425    23      92      72      72   \n",
       "5954        6139          6139  20150426     0      82      73      73   \n",
       "5955        6140          6140  20150426     1      67      69      69   \n",
       "5956        6141          6141  20150426     2      74      61      61   \n",
       "5957        6142          6142  20150426     3      61      53      53   \n",
       "5958        6143          6143  20150426     4      67      58      58   \n",
       "5959        6144          6144  20150426     5      67      61      61   \n",
       "5960        6145          6145  20150426     6      61      58      58   \n",
       "5961        6146          6146  20150426     7      54      58      58   \n",
       "5962        6147          6147  20150426     8      47      59      59   \n",
       "5963        6148          6148  20150426     9      43      51      51   \n",
       "5964        6149          6149  20150426    10      39      40      40   \n",
       "5965        6150          6150  20150426    11      33      34      34   \n",
       "5966        6151          6151  20150426    12      43      38      38   \n",
       "\n",
       "      PM25_4  PM25_5  PM25_6     ...       CO_1   CO_2   CO_3   CO_4   CO_5  \\\n",
       "5822      10      21      19     ...      0.711  0.693  1.034  0.390  0.688   \n",
       "5823      19      26      23     ...      0.715  0.793  0.914  0.370  0.707   \n",
       "5824      20      31      24     ...      1.477  1.153  0.879  0.451  0.720   \n",
       "5825      17      32      21     ...      0.896  1.163  0.921  0.573  0.800   \n",
       "5826      30      38      28     ...      0.721  0.946  1.011  0.699  0.914   \n",
       "5827      41      43      40     ...      0.670  0.685  0.982  0.650  0.933   \n",
       "5828      37      47      36     ...      0.606  0.719  0.920  0.551  0.815   \n",
       "5829      34      39      31     ...      0.728  0.971  0.924  0.457  0.783   \n",
       "5830      28      34      30     ...      0.751  1.136  0.966  0.517  0.785   \n",
       "5831      32      38      36     ...      0.787  1.154  1.034  0.516  0.821   \n",
       "5832      42      39      37     ...      0.775  1.088  1.046  0.677  0.833   \n",
       "5833      53      51      46     ...      0.779  0.785  1.082  1.015  0.796   \n",
       "5834      55      56      53     ...      0.817  0.761  1.063  0.837  0.883   \n",
       "5835      59      68      49     ...      0.814  0.820  1.067  0.707  0.883   \n",
       "5836      68      73      25     ...      0.833  0.836  1.113  0.751  0.904   \n",
       "5837      62      81      74     ...      1.007  1.178  1.183  0.509  0.951   \n",
       "5838      52      83      66     ...      1.328  0.889  1.054  0.478  0.853   \n",
       "5839      47      65      51     ...      1.084  2.214  1.000  0.523  0.749   \n",
       "5840      42      55      45     ...      0.925  2.060  1.016  0.483  0.697   \n",
       "5841      38      49      45     ...      0.869  1.004  0.999  0.458  0.640   \n",
       "5842      37      41      37     ...      0.952  1.138  1.006  0.414  0.618   \n",
       "5843      35      31      35     ...      1.142  1.548  1.008  0.410  0.608   \n",
       "5844      32      32      33     ...      1.120  1.002  1.031  0.374  0.695   \n",
       "5845      33      40      37     ...      1.065  1.128  1.035  0.381  0.759   \n",
       "5846      33      39      32     ...      1.066  1.060  1.049  0.384  0.765   \n",
       "5847      30      38      38     ...      0.869  0.947  1.018  0.377  0.855   \n",
       "5848      32      51      37     ...      0.843  0.771  1.057  0.385  0.989   \n",
       "5849      34      62      40     ...      0.906  0.852  1.045  0.624  0.918   \n",
       "5850      41      77      44     ...      0.953  0.948  1.147  0.785  0.969   \n",
       "5851      47      87      55     ...      1.048  1.136  1.339  0.908  0.950   \n",
       "...      ...     ...     ...     ...        ...    ...    ...    ...    ...   \n",
       "5937      95     118      87     ...      1.255  1.118  1.118  1.517  1.063   \n",
       "5938     104     123      90     ...      1.513  1.318  1.318  2.159  1.053   \n",
       "5939     111     127      94     ...      1.482  1.635  1.635  1.783  1.155   \n",
       "5940     111     137     101     ...      1.822  1.601  1.601  1.559  1.091   \n",
       "5941     118     132     100     ...      1.818  1.289  1.289  1.600  0.963   \n",
       "5942     104      99     109     ...      1.633  1.125  1.125  1.691  0.962   \n",
       "5943     107     151      78     ...      1.231  1.038  1.038  1.169  1.345   \n",
       "5944      81     121      60     ...      1.063  0.526  0.526  0.804  0.956   \n",
       "5945      70      87      59     ...      1.005  0.547  0.547  0.633  0.801   \n",
       "5946      60      57      71     ...      0.957  0.585  0.585  0.552  0.712   \n",
       "5947      47      47      56     ...      0.744  0.517  0.517  0.582  0.764   \n",
       "5948      50      41      39     ...      0.927  0.553  0.553  0.701  0.720   \n",
       "5949      62      36      44     ...      0.823  0.615  0.615  0.801  0.732   \n",
       "5950      71      40      49     ...      0.995  0.774  0.774  0.902  0.791   \n",
       "5951      75      66      63     ...      1.734  0.983  0.983  0.976  0.853   \n",
       "5952      79      94      80     ...      1.048  0.802  0.802  0.856  0.868   \n",
       "5953      82     103      86     ...      1.274  0.843  0.843  1.025  0.855   \n",
       "5954      86      87      78     ...      1.192  0.880  0.880  0.851  0.836   \n",
       "5955      81      82      71     ...      0.749  0.710  0.710  0.582  0.824   \n",
       "5956      55      75      59     ...      1.386  0.630  0.630  0.539  0.806   \n",
       "5957      48      65      49     ...      0.701  0.596  0.596  0.504  0.843   \n",
       "5958      50      74      56     ...      0.653  0.586  0.586  0.517  1.117   \n",
       "5959      52      73      59     ...      0.650  0.568  0.568  0.586  0.831   \n",
       "5960      53      65      52     ...      0.674  0.550  0.550  0.724  0.806   \n",
       "5961      52      66      50     ...      0.649  0.669  0.669  0.637  0.876   \n",
       "5962      50      64      45     ...      0.642  0.787  0.787  0.612  0.929   \n",
       "5963      41      63      40     ...      0.735  0.749  0.749  0.567  0.929   \n",
       "5964      39      52      36     ...      0.574  0.626  0.626  0.517  0.879   \n",
       "5965      33      43      37     ...      0.658  0.614  0.614  0.560  0.832   \n",
       "5966      41      45      43     ...      0.762  0.584  0.584  0.533  0.876   \n",
       "\n",
       "       CO_6   CO_7   CO_8   CO_9   PM25_mean  \n",
       "5822  0.726  0.415  0.332  0.677   20.888889  \n",
       "5823  0.567  0.433  0.364  0.699   24.666667  \n",
       "5824  0.493  0.452  0.582  0.716   26.111111  \n",
       "5825  0.543  0.529  0.679  0.775   24.222222  \n",
       "5826  0.614  0.574  0.813  0.901   35.444444  \n",
       "5827  0.584  0.533  0.726  0.862   43.222222  \n",
       "5828  0.510  0.469  0.695  0.756   41.111111  \n",
       "5829  0.519  0.490  0.578  0.722   36.333333  \n",
       "5830  0.640  0.542  0.616  0.765   34.555556  \n",
       "5831  0.732  0.567  0.677  0.815   38.777778  \n",
       "5832  0.685  0.659  0.777  0.845   42.111111  \n",
       "5833  0.684  0.692  0.892  1.076   45.888889  \n",
       "5834  0.664  0.630  0.572  1.148   51.888889  \n",
       "5835  0.680  0.628  0.564  1.036   60.222222  \n",
       "5836  0.753  0.671  0.592  1.049   63.555556  \n",
       "5837  0.722  0.597  0.557  0.736   69.555556  \n",
       "5838  0.610  0.563  0.456  0.681   64.777778  \n",
       "5839  0.565  0.503  0.680  0.651   50.333333  \n",
       "5840  0.596  0.498  0.718  0.622   45.888889  \n",
       "5841  0.526  0.490  0.872  0.604   44.222222  \n",
       "5842  0.491  0.489  0.634  0.560   40.000000  \n",
       "5843  0.503  0.483  0.748  0.547   37.666667  \n",
       "5844  0.485  0.490  0.515  0.576   37.222222  \n",
       "5845  0.487  0.510  0.552  0.616   37.000000  \n",
       "5846  0.477  0.479  0.453  0.633   36.000000  \n",
       "5847  0.481  0.465  0.404  0.640   36.666667  \n",
       "5848  0.636  0.451  0.554  0.640   38.666667  \n",
       "5849  0.623  0.457  0.878  0.641   43.000000  \n",
       "5850  0.685  0.628  0.960  0.728   47.555556  \n",
       "5851  0.890  0.673  1.080  0.979   54.333333  \n",
       "...     ...    ...    ...    ...         ...  \n",
       "5937  1.298  0.808  0.808  1.229   97.777778  \n",
       "5938  1.414  0.852  0.852  1.266   99.666667  \n",
       "5939  1.552  1.003  1.003  1.471  104.444444  \n",
       "5940  1.582  1.141  1.141  1.485  113.222222  \n",
       "5941  1.660  1.298  1.298  1.366  117.111111  \n",
       "5942  1.569  1.225  1.225  1.463  101.222222  \n",
       "5943  0.975  0.872  0.872  1.097   94.444444  \n",
       "5944  0.525  0.473  0.473  0.850   72.000000  \n",
       "5945  0.479  0.376  0.376  0.878   65.444444  \n",
       "5946  0.524  0.393  0.393  0.872   59.111111  \n",
       "5947  0.498  0.394  0.394  0.939   46.777778  \n",
       "5948  0.542  0.454  0.454  1.069   43.777778  \n",
       "5949  0.664  0.541  0.541  1.135   46.111111  \n",
       "5950  0.747  0.562  0.562  1.147   53.111111  \n",
       "5951  0.918  0.569  0.569  1.080   67.666667  \n",
       "5952  0.876  0.622  0.622  0.959   82.111111  \n",
       "5953  0.830  0.709  0.709  0.956   83.444444  \n",
       "5954  0.688  0.656  0.656  0.867   79.666667  \n",
       "5955  0.676  0.466  0.466  0.832   72.555556  \n",
       "5956  0.524  0.333  0.333  0.810   60.555556  \n",
       "5957  0.494  0.351  0.351  0.792   53.000000  \n",
       "5958  0.484  0.330  0.330  0.837   58.000000  \n",
       "5959  0.457  0.332  0.332  0.833   59.222222  \n",
       "5960  0.463  0.342  0.342  0.787   56.000000  \n",
       "5961  0.503  0.374  0.374  0.759   55.666667  \n",
       "5962  0.510  0.397  0.397  0.723   52.444444  \n",
       "5963  0.501  0.332  0.332  0.711   44.222222  \n",
       "5964  0.453  0.304  0.304  0.684   38.777778  \n",
       "5965  0.497  0.355  0.355  0.753   34.000000  \n",
       "5966  0.495  0.361  0.361  0.804   41.666667  \n",
       "\n",
       "[145 rows x 59 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [:,4:59]\n",
    "i=22\n",
    "data.iloc[5800+i:5969-24+i,:59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(time_m_,w_m_,wea_m_,ge_m_,sd_m_, Tx=20, Ty=25):\n",
    "    \"\"\"\n",
    "    可视化Attention层\n",
    "    \n",
    "    @param sentence: 待翻译的句子，str类型\n",
    "    @param Tx: 输入句子的长度\n",
    "    @param Ty: 输出句子的长度\n",
    "    \"\"\"\n",
    "\n",
    "#     X = np.array(text_to_int(sentence, source_vocab_to_int))\n",
    "    f = K.function(model.inputs, [model.layers[9].get_output_at(t) for t in range(Ty)])\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    out0 = np.zeros((1, len(target_vocab_to_int)))\n",
    "    \n",
    "    r = f([X.reshape(-1,20), s0, c0, out0])\n",
    "    \n",
    "    attention_map = np.zeros((Ty, Tx))\n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0, t_prime, 0]\n",
    "    \n",
    "    Y = make_prediction(sentence)\n",
    "    \n",
    "    source_list = sentence.split()\n",
    "    target_list = Y.split()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20,15))\n",
    "    sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras.layers\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Convolution1D, Dense\n",
    "from keras.models import Input, Model\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def channel_normalization(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\" Normalize a layer to the maximum activation\n",
    "\n",
    "    This keeps a layers values between zero and one.\n",
    "    It helps with relu's unbounded activation\n",
    "\n",
    "    Args:\n",
    "        x: The layer to normalize\n",
    "\n",
    "    Returns:\n",
    "        A maximal normalized layer\n",
    "    \"\"\"\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "\n",
    "def wave_net_activation(x):\n",
    "    # type: (Layer) -> Layer\n",
    "    \"\"\"This method defines the activation used for WaveNet\n",
    "\n",
    "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
    "\n",
    "    Args:\n",
    "        x: The layer we want to apply the activation to\n",
    "\n",
    "    Returns:\n",
    "        A new layer with the wavenet activation applied\n",
    "    \"\"\"\n",
    "    tanh_out = Activation('tanh')(x)\n",
    "    sigm_out = Activation('sigmoid')(x)\n",
    "    return keras.layers.multiply([tanh_out, sigm_out])\n",
    "\n",
    "\n",
    "def residual_block(x, s, i, c, activation, nb_filters, kernel_size, padding, dropout_rate=0):\n",
    "    # type: (Layer, int, int, int, str, int, int, str, float, str) -> Tuple[Layer, Layer]\n",
    "    \"\"\"Defines the residual block for the WaveNet TCN\n",
    "\n",
    "    Args:\n",
    "        x: The previous layer in the model\n",
    "        s: The stack index i.e. which stack in the overall TCN\n",
    "        i: The dilation power of 2 we are using for this residual block\n",
    "        c: The dilation name to make it unique. In case we have same dilation twice: [1, 1, 2, 4].\n",
    "        activation: The name of the type of activation to use\n",
    "        nb_filters: The number of convolutional filters to use in this block\n",
    "        kernel_size: The size of the convolutional kernel\n",
    "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A tuple where the first element is the residual model layer, and the second\n",
    "        is the skip connection.\n",
    "    \"\"\"\n",
    "\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding=padding)(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "    elif activation == 'wavenet':\n",
    "        x = wave_net_activation(conv)\n",
    "    else:\n",
    "        x = Activation(activation)(conv)\n",
    "\n",
    "    x = SpatialDropout1D(dropout_rate)(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = keras.layers.add([original_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        # print(f'Updated dilations from {dilations} to {new_dilations} because of backwards compatibility.')\n",
    "        return new_dilations\n",
    "\n",
    "\n",
    "class TCN:\n",
    "    \"\"\"Creates a TCN layer.\n",
    "\n",
    "        Input shape:\n",
    "            A tensor of shape (batch_size, timesteps, input_dim).\n",
    "\n",
    "        Args:\n",
    "            nb_filters: The number of filters to use in the convolutional layers.\n",
    "            kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "            dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "            nb_stacks : The number of stacks of residual blocks to use.\n",
    "            activation: The activations to use (norm_relu, wavenet, relu...).\n",
    "            padding: The padding to use in the convolutional layers, 'causal' or 'same'.\n",
    "            use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "            return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "            name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "        Returns:\n",
    "            A TCN layer.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=[1, 2, 4, 8, 16, 32],\n",
    "                 activation='norm_relu',\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.0,\n",
    "                 return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.activation = activation\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding != 'causal' and padding != 'same':\n",
    "            raise ValueError(\"Only 'causal' or 'same' padding are compatible for this layer.\")\n",
    "\n",
    "        if not isinstance(nb_filters, int):\n",
    "            print('An interface change occurred after the version 2.1.2.')\n",
    "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
    "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
    "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
    "            raise Exception()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        x = Convolution1D(self.nb_filters, 1, padding=self.padding)(x)\n",
    "        skip_connections = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for i, d in enumerate(self.dilations):\n",
    "                x, skip_out = residual_block(x, s, d, i, self.activation, self.nb_filters,\n",
    "                                             self.kernel_size, self.padding, self.dropout_rate)\n",
    "                skip_connections.append(skip_out)\n",
    "        if self.use_skip_connections:\n",
    "            x = keras.layers.add(skip_connections)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        if not self.return_sequences:\n",
    "            output_slice_index = -1\n",
    "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def compiled_tcn(num_feat,  # type: int\n",
    "                 num_classes,  # type: int\n",
    "                 nb_filters,  # type: int\n",
    "                 kernel_size,  # type: int\n",
    "                 dilations,  # type: List[int]\n",
    "                 nb_stacks,  # type: int\n",
    "                 max_len,  # type: int\n",
    "                 activation='norm_relu',  # type: str\n",
    "                 padding='causal',  # type: str\n",
    "                 use_skip_connections=True,  # type: bool\n",
    "                 return_sequences=True,\n",
    "                 regression=False,  # type: bool\n",
    "                 dropout_rate=0.05,  # type: float\n",
    "                 ):\n",
    "    # type: (...) -> keras.Model\n",
    "    \"\"\"Creates a compiled TCN model for a given task (i.e. regression or classification).\n",
    "\n",
    "    Args:\n",
    "        num_feat: The number of features of your input, i.e. the last dimension of: (batch_size, timesteps, input_dim).\n",
    "        num_classes: The size of the final dense layer, how many classes we are predicting.\n",
    "        nb_filters: The number of filters to use in the convolutional layers.\n",
    "        kernel_size: The size of the kernel to use in each convolutional layer.\n",
    "        dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
    "        nb_stacks : The number of stacks of residual blocks to use.\n",
    "        max_len: The maximum sequence length, use None if the sequence length is dynamic.\n",
    "        activation: The activations to use.\n",
    "        padding: The padding to use in the convolutional layers.\n",
    "        use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
    "        return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "        regression: Whether the output should be continuous or discrete.\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        name: Name of the model. Useful when having multiple TCN.\n",
    "\n",
    "    Returns:\n",
    "        A compiled keras TCN.\n",
    "    \"\"\"\n",
    "\n",
    "    dilations = process_dilations(dilations)\n",
    "\n",
    "    input_layer = Input(shape=(max_len, num_feat))\n",
    "\n",
    "    x = TCN(nb_filters, kernel_size, nb_stacks, dilations, activation,\n",
    "            padding, use_skip_connections, dropout_rate, return_sequences)(input_layer)\n",
    "\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "    if not regression:\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO To remove later.\n",
    "        def accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            if K.ndim(y_true) == K.ndim(y_pred):\n",
    "                y_true = K.squeeze(y_true, -1)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "            y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='sparse_categorical_crossentropy', metrics=[accuracy])\n",
    "        print('Adam with norm clipping.')\n",
    "    else:\n",
    "        # regression\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('linear')(x)\n",
    "        output_layer = x\n",
    "        print(f'model.x = {input_layer.shape}')\n",
    "        print(f'model.y = {output_layer.shape}')\n",
    "        model = Model(input_layer, output_layer)\n",
    "        adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "        model.compile(adam, loss='mean_squared_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
