{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, GRU, Multiply, Reshape\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "# from tcn import TCN\n",
    "%matplotlib inline\n",
    "from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   \n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, GlobalMaxPooling2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, GlobalAveragePooling2D,AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm\n",
    "MAX_SENT_LENGTH = 55\n",
    "MAX_SENTS = 24\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from pandas import concat\n",
    "\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#matplotlib inline\n",
    "#参数初始化\n",
    "discfile = '../data/data_wea_time_unify.csv'\n",
    "\n",
    "data = pd.read_csv(discfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "ground = h5py.File('../data/inte_g_12_linear.h5', 'r')\n",
    "g = ground['X']\n",
    "\n",
    "ele_zs = h5py.File('../data/inte_e_zs_12_new_linear.h5', 'r')\n",
    "ezs = ele_zs['X']\n",
    "\n",
    "ele_sd = h5py.File('../data/inte_e_sd_12_new_linear.h5', 'r')\n",
    "esd = ele_sd['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_m=[g,ezs,esd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_m=np.array(g_m).reshape(6064,16,16,3)\n",
    "g=np.array(g).reshape(6064,16,16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4850 samples, validate on 1213 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [3876,1] vs. [68,1]\n\t [[Node: training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Shape, training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Shape_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c649acd98fd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6063\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6063\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM25_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;31m# 绘制训练 & 验证的损失值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [3876,1] vs. [68,1]\n\t [[Node: training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Shape, training_3/Adam/gradients/loss_3/dense_37_loss/sub_grad/Shape_1)]]"
     ]
    }
   ],
   "source": [
    "# from attention_keras import *\n",
    "from keras.layers import LeakyReLU\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(** kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        # W.shape = (time_steps, time_steps)\n",
    "        self.W = self.add_weight(name='att_weight', \n",
    "                                 shape=(input_shape[1], input_shape[1]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = K.permute_dimensions(inputs, (0, 2, 1))\n",
    "        # x.shape = (batch_size, seq_len, time_steps)\n",
    "        a = K.softmax(K.tanh(K.dot(x, self.W)))\n",
    "        a = K.permute_dimensions(a, (0, 2, 1))\n",
    "#         outputs = a * inputs\n",
    "# #         outputs = K.sum(outputs, axis=1)\n",
    "# #         outputs = K.permute_dimensions(a * inputs, (0, 2, 1))\n",
    "#         outputs = K.sum(outputs, axis=0)\n",
    "    \n",
    "        outputs=Multiply()([a,inputs])\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[2]\n",
    "\n",
    "def create_model(learn_rate=0.001, neurons=24, traffic_n=3):    \n",
    "#     交通指数数据模块\n",
    "    inp=Input(shape=(16, 16, 1))\n",
    "    out=Conv2D(filters=1, kernel_size=3, strides=1)(inp)\n",
    "    out=MaxPooling2D(pool_size=(3, 3), strides=2)(out)\n",
    "    out=Flatten()(out)\n",
    "\n",
    "    out=Dense(3)(out)\n",
    "\n",
    "    \n",
    "#     特征组件\n",
    "    sentence_input = Input(shape=(54,))\n",
    "    s_input=keras.layers.concatenate([sentence_input,out ])\n",
    "    embed = Reshape((54+3,1))(s_input)\n",
    "#     embed = AttentionLayer()(embed)\n",
    "#     embed = Reshape((54+3,1))(embed)\n",
    "    l_lstm=MAttention(8,16)([embed,embed,embed])\n",
    "    l_dense = TimeDistributed(Dense(32))(l_lstm)\n",
    "\n",
    "    l_att = AttentionLayer()(l_dense)\n",
    "\n",
    "    preds = Dense(1)(l_att)\n",
    "    model_1 = Model([inp,sentence_input], preds)\n",
    "    model_1.compile(optimizer=Adam(lr=learn_rate, beta_1=0.99, beta_2=0.999, decay=0.0006),\n",
    "                        loss='mae')\n",
    "    return model_1\n",
    "\n",
    "model=create_model()\n",
    "history=model.fit([g[:6063],data.iloc[:6063,4:58]],data['PM25_mean'][1:], epochs=20, batch_size=68,verbose=2,validation_split=0.2,shuffle=True)\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16, 16, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 1)    10          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 1)      0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 36)           0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            111         flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 57)           0           input_5[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 57, 1)        0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "m_attention_1 (MAttention)      (None, 57, 128)      384         reshape_2[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 57, 32)       4128        m_attention_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_1 (AttentionLay (None, 32)           3249        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            33          attention_layer_1[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = K.function(tra.inputs, [tra.get_layer('dense_27').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def to_mask(x, mask, mode='mul'):\n",
    "    \"\"\"通用mask函数\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        return x\n",
    "    else:\n",
    "        for _ in range(K.ndim(x) - K.ndim(mask)):\n",
    "            mask = K.expand_dims(mask, K.ndim(mask))\n",
    "        if mode == 'mul':\n",
    "            return x * mask\n",
    "        else:\n",
    "            return x - (1 - mask) * 1e10\n",
    "\n",
    "class OurLayer(Layer):\n",
    "    \"\"\"定义新的Layer，增加reuse方法，允许在定义Layer时调用现成的层\n",
    "    \"\"\"\n",
    "    def reuse(self, layer, *args, **kwargs):\n",
    "        if not layer.built:\n",
    "            if len(args) > 0:\n",
    "                inputs = args[0]\n",
    "            else:\n",
    "                inputs = kwargs['inputs']\n",
    "            if isinstance(inputs, list):\n",
    "                input_shape = [K.int_shape(x) for x in inputs]\n",
    "            else:\n",
    "                input_shape = K.int_shape(inputs)\n",
    "            layer.build(input_shape)\n",
    "        outputs = layer.call(*args, **kwargs)\n",
    "        for w in layer.trainable_weights:\n",
    "            if w not in self._trainable_weights:\n",
    "                self._trainable_weights.append(w)\n",
    "        for w in layer.non_trainable_weights:\n",
    "            if w not in self._non_trainable_weights:\n",
    "                self._non_trainable_weights.append(w)\n",
    "        return outputs\n",
    "class MAttention(OurLayer):\n",
    "    \"\"\"多头注意力机制\n",
    "    \"\"\"\n",
    "    def __init__(self, heads=8, size_per_head=16, key_size=None,\n",
    "                 mask_right=False, **kwargs):\n",
    "        super(MAttention, self).__init__(**kwargs)\n",
    "        self.heads = heads\n",
    "        self.size_per_head = size_per_head\n",
    "        self.out_dim = heads * size_per_head\n",
    "        self.key_size = key_size if key_size else size_per_head\n",
    "        self.mask_right = mask_right\n",
    "    def build(self, input_shape):\n",
    "        super(MAttention, self).build(input_shape)\n",
    "        self.q_dense = Dense(self.key_size * self.heads, use_bias=False)\n",
    "        self.k_dense = Dense(self.key_size * self.heads, use_bias=False)\n",
    "        self.v_dense = Dense(self.out_dim, use_bias=False)\n",
    "    def get_config(self):\n",
    "        config = {'heads': self.heads,'size_per_head': self.size_per_head}\n",
    "        base_config = super(MAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        q, k, v = inputs[: 3]\n",
    "        v_mask, q_mask = None, None\n",
    "        if len(inputs) > 3:\n",
    "            v_mask = inputs[3]\n",
    "            if len(inputs) > 4:\n",
    "                q_mask = inputs[4]\n",
    "        # 线性变换\n",
    "        qw = self.reuse(self.q_dense, q)\n",
    "        kw = self.reuse(self.k_dense, k)\n",
    "        vw = self.reuse(self.v_dense, v)\n",
    "        # 形状变换\n",
    "        qw = K.reshape(qw, (-1, K.shape(qw)[1], self.heads, self.key_size))\n",
    "        kw = K.reshape(kw, (-1, K.shape(kw)[1], self.heads, self.key_size))\n",
    "        vw = K.reshape(vw, (-1, K.shape(vw)[1], self.heads, self.size_per_head))\n",
    "        # 维度置换\n",
    "        qw = K.permute_dimensions(qw, (0, 2, 1, 3))\n",
    "        kw = K.permute_dimensions(kw, (0, 2, 1, 3))\n",
    "        vw = K.permute_dimensions(vw, (0, 2, 1, 3))\n",
    "        # Attention\n",
    "        a = K.batch_dot(qw, kw, [3, 3]) / self.key_size**0.5\n",
    "        a = K.permute_dimensions(a, (0, 3, 2, 1))\n",
    "        a = to_mask(a, v_mask, 'add')\n",
    "        a = K.permute_dimensions(a, (0, 3, 2, 1))\n",
    "        if (self.mask_right is not False) or (self.mask_right is not None):\n",
    "            if self.mask_right is True:\n",
    "                ones = K.ones_like(a[: 1, : 1])\n",
    "                mask = (ones - K.tf.matrix_band_part(ones, -1, 0)) * 1e10\n",
    "                a = a - mask\n",
    "            else:\n",
    "                # 这种情况下，mask_right是外部传入的0/1矩阵，shape=[q_len, k_len]\n",
    "                mask = (1 - K.constant(self.mask_right)) * 1e10\n",
    "                mask = K.expand_dims(K.expand_dims(mask, 0), 0)\n",
    "                self.mask = mask\n",
    "                a = a - mask\n",
    "        a = K.softmax(a)\n",
    "        self.a = a\n",
    "        # 完成输出\n",
    "        o = K.batch_dot(a, vw, [3, 2])\n",
    "        o = K.permute_dimensions(o, (0, 2, 1, 3))\n",
    "        o = K.reshape(o, (-1, K.shape(o)[1], self.out_dim))\n",
    "        o = to_mask(o, q_mask, 'mul')\n",
    "        return o\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
